{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Preprocessing data...\n",
      "Analyzing class distribution...\n",
      "Minimum samples in a class: 1\n",
      "Class distribution before oversampling:\n",
      "Class 0: 2 samples\n",
      "Class 1: 1032 samples\n",
      "Class 2: 2 samples\n",
      "Class 3: 4 samples\n",
      "Class 4: 277 samples\n",
      "Class 5: 18 samples\n",
      "Class 6: 6767 samples\n",
      "Class 7: 463 samples\n",
      "Class 8: 3820 samples\n",
      "Class 9: 3828 samples\n",
      "Class 10: 3955 samples\n",
      "Class 11: 16 samples\n",
      "Class 12: 3371 samples\n",
      "Class 13: 4148 samples\n",
      "Class 14: 5031 samples\n",
      "Class 15: 293 samples\n",
      "Class 16: 158 samples\n",
      "Class 17: 9 samples\n",
      "Class 18: 57 samples\n",
      "Class 19: 1900 samples\n",
      "Class 20: 2429 samples\n",
      "Class 21: 3037 samples\n",
      "Class 22: 291 samples\n",
      "Class 23: 961 samples\n",
      "Class 24: 733 samples\n",
      "Class 25: 844 samples\n",
      "Class 26: 115 samples\n",
      "Class 27: 78 samples\n",
      "Class 28: 1 samples\n",
      "Class 29: 79 samples\n",
      "Class 30: 2 samples\n",
      "Class 31: 2 samples\n",
      "Class 32: 33 samples\n",
      "Class 33: 5 samples\n",
      "Using RandomOverSampler for oversampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ddihora1604\\AppData\\Local\\Temp\\ipykernel_18132\\3182842752.py:162: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution after oversampling:\n",
      "Class 0: 6767 samples\n",
      "Class 1: 6767 samples\n",
      "Class 2: 6767 samples\n",
      "Class 3: 6767 samples\n",
      "Class 4: 6767 samples\n",
      "Class 5: 6767 samples\n",
      "Class 6: 6767 samples\n",
      "Class 7: 6767 samples\n",
      "Class 8: 6767 samples\n",
      "Class 9: 6767 samples\n",
      "Class 10: 6767 samples\n",
      "Class 11: 6767 samples\n",
      "Class 12: 6767 samples\n",
      "Class 13: 6767 samples\n",
      "Class 14: 6767 samples\n",
      "Class 15: 6767 samples\n",
      "Class 16: 6767 samples\n",
      "Class 17: 6767 samples\n",
      "Class 18: 6767 samples\n",
      "Class 19: 6767 samples\n",
      "Class 20: 6767 samples\n",
      "Class 21: 6767 samples\n",
      "Class 22: 6767 samples\n",
      "Class 23: 6767 samples\n",
      "Class 24: 6767 samples\n",
      "Class 25: 6767 samples\n",
      "Class 26: 6767 samples\n",
      "Class 27: 6767 samples\n",
      "Class 28: 6767 samples\n",
      "Class 29: 6767 samples\n",
      "Class 30: 6767 samples\n",
      "Class 31: 6767 samples\n",
      "Class 32: 6767 samples\n",
      "Class 33: 6767 samples\n",
      "Training fold 1/2...\n",
      "Training fold 2/2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Metrics Across Folds:\n",
      "       Classifier  Fold  Class  Accuracy  Precision  Recall  F1 Score  \\\n",
      "0  RotationForest     1      0  1.000000   1.000000     1.0  1.000000   \n",
      "1  RotationForest     1      1  0.999896   0.996419     1.0  0.998206   \n",
      "2  RotationForest     1      2  1.000000   1.000000     1.0  1.000000   \n",
      "3  RotationForest     1      3  1.000000   1.000000     1.0  1.000000   \n",
      "4  RotationForest     1      4  0.999991   0.999707     1.0  0.999854   \n",
      "\n",
      "   Matthews Correlation Coefficient  Cohen Kappa  True Positive Rate (TPR)  \\\n",
      "0                          1.000000     1.000000                       1.0   \n",
      "1                          0.998154     0.998153                       1.0   \n",
      "2                          1.000000     1.000000                       1.0   \n",
      "3                          1.000000     1.000000                       1.0   \n",
      "4                          0.999849     0.999849                       1.0   \n",
      "\n",
      "   True Negative Rate (TNR)  False Positive Rate (FPR)  \\\n",
      "0                  1.000000                   0.000000   \n",
      "1                  0.999893                   0.000107   \n",
      "2                  1.000000                   0.000000   \n",
      "3                  1.000000                   0.000000   \n",
      "4                  0.999991                   0.000009   \n",
      "\n",
      "   False Negative Rate (FNR)  Training Time (s)  Testing Time (s)  \n",
      "0                        0.0           21.33575          0.766932  \n",
      "1                        0.0           21.33575          0.766932  \n",
      "2                        0.0           21.33575          0.766932  \n",
      "3                        0.0           21.33575          0.766932  \n",
      "4                        0.0           21.33575          0.766932  \n",
      "\n",
      "Average Metrics Across Folds:\n",
      "        Classifier  Class  Accuracy  Precision    Recall  F1 Score\n",
      "0   RotationForest      0  1.000000   1.000000  1.000000  1.000000\n",
      "1   RotationForest      1  0.999874   0.996030  0.999708  0.997866\n",
      "2   RotationForest      2  1.000000   1.000000  1.000000  1.000000\n",
      "3   RotationForest      3  1.000000   1.000000  1.000000  1.000000\n",
      "4   RotationForest      4  0.999987   0.999555  1.000000  0.999778\n",
      "5   RotationForest      5  1.000000   1.000000  1.000000  1.000000\n",
      "6   RotationForest      6  0.999957   1.000000  0.998521  0.999260\n",
      "7   RotationForest      7  0.999983   0.999409  1.000000  0.999704\n",
      "8   RotationForest      8  0.999983   0.999851  0.999556  0.999704\n",
      "9   RotationForest      9  0.999970   1.000000  0.998967  0.999483\n",
      "10  RotationForest     10  0.999943   1.000000  0.998080  0.999038\n",
      "11  RotationForest     11  0.999996   0.999853  1.000000  0.999927\n",
      "12  RotationForest     12  0.999987   0.999852  0.999703  0.999778\n",
      "13  RotationForest     13  0.999900   0.999259  0.997340  0.998298\n",
      "14  RotationForest     14  0.999935   0.999261  0.998524  0.998892\n",
      "15  RotationForest     15  0.999970   0.998966  1.000000  0.999483\n",
      "16  RotationForest     16  0.999996   0.999854  1.000000  0.999927\n",
      "17  RotationForest     17  1.000000   1.000000  1.000000  1.000000\n",
      "18  RotationForest     18  0.999970   0.998971  1.000000  0.999485\n",
      "19  RotationForest     19  0.999891   0.999113  0.997212  0.998160\n",
      "20  RotationForest     20  0.999904   0.998248  0.998508  0.998377\n",
      "21  RotationForest     21  0.999917   0.998969  0.998240  0.998604\n",
      "22  RotationForest     22  0.999948   0.998235  1.000000  0.999116\n",
      "23  RotationForest     23  1.000000   1.000000  1.000000  1.000000\n",
      "24  RotationForest     24  1.000000   1.000000  1.000000  1.000000\n",
      "25  RotationForest     25  1.000000   1.000000  1.000000  1.000000\n",
      "26  RotationForest     26  0.999996   0.999852  1.000000  0.999926\n",
      "27  RotationForest     27  0.999205   0.999229  0.973703  0.986301\n",
      "28  RotationForest     28  1.000000   1.000000  1.000000  1.000000\n",
      "29  RotationForest     29  0.999226   0.974377  1.000000  0.987022\n",
      "30  RotationForest     30  1.000000   1.000000  1.000000  1.000000\n",
      "31  RotationForest     31  1.000000   1.000000  1.000000  1.000000\n",
      "32  RotationForest     32  0.999996   0.999850  1.000000  0.999925\n",
      "33  RotationForest     33  1.000000   1.000000  1.000000  1.000000\n",
      "Rotation Forest implementation completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             balanced_accuracy_score, confusion_matrix,\n",
    "                             matthews_corrcoef, cohen_kappa_score)\n",
    "import time\n",
    "import os\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the number of K folds\n",
    "K_FOLDS = 2\n",
    "\n",
    "# Create directories to save results\n",
    "os.makedirs(\"confusion_matrices\", exist_ok=True)\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Helper function for confusion matrix metrics\n",
    "def confusion_matrix_metrics(cm, classes):\n",
    "    metrics = {}\n",
    "    for idx, class_label in enumerate(classes):\n",
    "        TP = cm[idx, idx]  # True Positives for this class\n",
    "        FP = cm[:, idx].sum() - TP  # False Positives for this class\n",
    "        FN = cm[idx, :].sum() - TP  # False Negatives for this class\n",
    "        TN = cm.sum() - (TP + FP + FN)  # True Negatives for this class\n",
    "\n",
    "        metrics[class_label] = {\n",
    "            'TPR': TP / (TP + FN + 1e-10) if (TP + FN) > 0 else 0,\n",
    "            'TNR': TN / (TN + FP + 1e-10) if (TN + FP) > 0 else 0,\n",
    "            'FPR': FP / (FP + TN + 1e-10) if (FP + TN) > 0 else 0,\n",
    "            'FNR': FN / (FN + TP + 1e-10) if (FN + TP) > 0 else 0\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "# Rotation Forest implementation\n",
    "class RotationForestClassifier:\n",
    "    def __init__(self, n_estimators=10, feature_groups=3, max_features=0.75, random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.feature_groups = feature_groups\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        self.estimators = []\n",
    "        self.feature_indices = []\n",
    "        self.pcas = []\n",
    "        self.feature_importances_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.estimators = []\n",
    "        self.feature_indices = []\n",
    "        self.pcas = []\n",
    "        \n",
    "        # Initialize feature importance\n",
    "        all_importances = np.zeros((self.n_estimators, n_features))\n",
    "        \n",
    "        # Set random seed for reproducibility\n",
    "        np.random.seed(self.random_state)\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            # Randomly determine number of features per group\n",
    "            max_features = int(n_features * self.max_features) if isinstance(self.max_features, float) else self.max_features\n",
    "            features_per_group = max(1, max_features // self.feature_groups)\n",
    "            \n",
    "            # Shuffle feature indices\n",
    "            feature_indices = np.random.permutation(n_features)\n",
    "            \n",
    "            # Group features\n",
    "            groups = [feature_indices[j:j+features_per_group] for j in range(0, len(feature_indices), features_per_group)]\n",
    "            \n",
    "            # Create rotation matrix (identity initially)\n",
    "            R = np.zeros((n_features, n_features))\n",
    "            \n",
    "            # Apply PCA on each group\n",
    "            for group in groups:\n",
    "                if len(group) > 0:\n",
    "                    # Select subset of data for this group\n",
    "                    X_subset = X[:, group]\n",
    "                    \n",
    "                    # Apply PCA\n",
    "                    pca = PCA(random_state=self.random_state+i)\n",
    "                    pca.fit(X_subset)\n",
    "                    \n",
    "                    # Fill the rotation matrix with the PCA components\n",
    "                    for j, idx in enumerate(group):\n",
    "                        if j < len(pca.components_):\n",
    "                            for k, comp_idx in enumerate(group):\n",
    "                                if k < len(pca.components_[j]):\n",
    "                                    R[idx, comp_idx] = pca.components_[j, k]\n",
    "            \n",
    "            # Transform the data\n",
    "            X_transformed = X @ R\n",
    "            \n",
    "            # Train a decision tree on the transformed data\n",
    "            tree = DecisionTreeClassifier(random_state=self.random_state+i)\n",
    "            tree.fit(X_transformed, y)\n",
    "            \n",
    "            # Store the estimator, rotation matrix, and feature indices\n",
    "            self.estimators.append(tree)\n",
    "            self.feature_indices.append(feature_indices)\n",
    "            self.pcas.append(R)\n",
    "            \n",
    "            # Get feature importances from this tree\n",
    "            importance = np.zeros(n_features)\n",
    "            for idx, imp in zip(range(n_features), tree.feature_importances_):\n",
    "                importance[idx] = imp\n",
    "            all_importances[i] = importance\n",
    "        \n",
    "        # Average feature importances across all trees\n",
    "        self.feature_importances_ = np.mean(all_importances, axis=0)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((X.shape[0], len(self.estimators)))\n",
    "        \n",
    "        for i, (tree, R) in enumerate(zip(self.estimators, self.pcas)):\n",
    "            # Transform the data using the rotation matrix\n",
    "            X_transformed = X @ R\n",
    "            \n",
    "            # Make predictions\n",
    "            predictions[:, i] = tree.predict(X_transformed)\n",
    "        \n",
    "        # Majority voting\n",
    "        return np.array([np.bincount(predictions[i, :].astype(int)).argmax() for i in range(X.shape[0])])\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        probas = np.zeros((X.shape[0], len(np.unique(self.estimators[0].predict(X @ self.pcas[0])))))\n",
    "        \n",
    "        for i, (tree, R) in enumerate(zip(self.estimators, self.pcas)):\n",
    "            # Transform the data using the rotation matrix\n",
    "            X_transformed = X @ R\n",
    "            \n",
    "            # Make probability predictions\n",
    "            probas += tree.predict_proba(X_transformed)\n",
    "        \n",
    "        # Average probabilities\n",
    "        return probas / len(self.estimators)\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('C:/Users/ddihora1604/Downloads/IIT Patna/Darshan_Dihora_ID_17_Task_2/Dataset 2/part-00001_preprocessed_dataset.csv')\n",
    "\n",
    "# Take 20% of the data for faster processing (optional, comment out if you want to use full dataset)\n",
    "df = df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "# Rename the last column as 'label' if it's not already named that\n",
    "df.rename(columns={df.columns[-1]: 'label'}, inplace=True)\n",
    "\n",
    "# Preprocessing: Handle missing values\n",
    "print(\"Preprocessing data...\")\n",
    "# Replace NaN values with column means for numerical columns\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# For categorical columns, fill with mode\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col != 'label':  # Don't replace label\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical features if any\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col != 'label':  # Don't encode label yet\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Encode the label column\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Extract features and target\n",
    "X = df.drop(columns=['label']).values\n",
    "y = df['label'].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Apply oversampling for handling class imbalance\n",
    "print(\"Analyzing class distribution...\")\n",
    "class_counts = np.bincount(y)\n",
    "min_samples_per_class = min(count for count in class_counts if count > 0)\n",
    "\n",
    "print(f\"Minimum samples in a class: {min_samples_per_class}\")\n",
    "print(\"Class distribution before oversampling:\")\n",
    "for i, count in enumerate(class_counts):\n",
    "    if count > 0:\n",
    "        class_label = class_names[i] if i < len(class_names) else i\n",
    "        print(f\"Class {class_label}: {count} samples\")\n",
    "\n",
    "# Determine appropriate oversampling strategy based on sample counts\n",
    "if min_samples_per_class >= 6:\n",
    "    print(\"Using ADASYN for oversampling...\")\n",
    "    oversampler = ADASYN(random_state=42)\n",
    "elif min_samples_per_class >= 3:\n",
    "    print(\"Using SMOTE with reduced neighbors for oversampling...\")\n",
    "    oversampler = SMOTE(random_state=42, k_neighbors=min_samples_per_class-1)\n",
    "else:\n",
    "    print(\"Using RandomOverSampler for oversampling...\")\n",
    "    oversampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "X, y = oversampler.fit_resample(X, y)\n",
    "\n",
    "# Visualize the distribution of classes after oversampling\n",
    "plt.figure(figsize=(10, 6))\n",
    "resampled_class_counts = pd.Series(label_encoder.inverse_transform(y)).value_counts()\n",
    "sns.barplot(x=resampled_class_counts.index, y=resampled_class_counts.values)\n",
    "plt.title('Class Distribution After Oversampling')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visualizations/class_distribution_after_oversampling.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nClass distribution after oversampling:\")\n",
    "for i in np.unique(y):\n",
    "    class_label = class_names[i] if i < len(class_names) else i\n",
    "    count = np.sum(y == i)\n",
    "    print(f\"Class {class_label}: {count} samples\")\n",
    "\n",
    "# Initialize to store results\n",
    "results = []\n",
    "timing_results = []\n",
    "\n",
    "# Create K-fold cross-validation\n",
    "kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Fold-wise training and evaluation\n",
    "fold_idx = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(f\"Training fold {fold_idx}/{K_FOLDS}...\")\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Initialize Rotation Forest\n",
    "    rotation_forest = RotationForestClassifier(n_estimators=10, feature_groups=3, random_state=42)\n",
    "    \n",
    "    # Record start time\n",
    "    start_train_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    rotation_forest.fit(X_train, y_train)\n",
    "    \n",
    "    train_time = time.time() - start_train_time\n",
    "    \n",
    "    # Make predictions\n",
    "    start_test_time = time.time()\n",
    "    y_pred = rotation_forest.predict(X_test)\n",
    "    test_time = time.time() - start_test_time\n",
    "    \n",
    "    # Record timing results\n",
    "    timing_results.append({\n",
    "        'Classifier': 'RotationForest',\n",
    "        'Fold': fold_idx,\n",
    "        'Training Time (s)': train_time,\n",
    "        'Testing Time (s)': test_time,\n",
    "        'Total Time (s)': train_time + test_time\n",
    "    })\n",
    "    \n",
    "    # Compute metrics\n",
    "    unique_classes = np.unique(y)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=unique_classes)\n",
    "    cm_metrics = confusion_matrix_metrics(cm, unique_classes)\n",
    "    \n",
    "    # Plot and save confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=[class_names[i] if i < len(class_names) else i for i in unique_classes],\n",
    "                yticklabels=[class_names[i] if i < len(class_names) else i for i in unique_classes])\n",
    "    plt.title(f\"Rotation Forest - Fold {fold_idx} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.savefig(f\"confusion_matrices/fold_{fold_idx}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate metrics per class\n",
    "    class_metrics_list = []\n",
    "    for class_label in unique_classes:\n",
    "        # Create binary labels for this class\n",
    "        y_test_bin = (y_test == class_label).astype(int)\n",
    "        y_pred_bin = (y_pred == class_label).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        class_specific_metrics = {\n",
    "            'Classifier': 'RotationForest',\n",
    "            'Fold': fold_idx,\n",
    "            'Class': class_names[class_label] if class_label < len(class_names) else class_label,\n",
    "            'Accuracy': accuracy_score(y_test_bin, y_pred_bin),\n",
    "            'Precision': precision_score(y_test_bin, y_pred_bin, zero_division=0),\n",
    "            'Recall': recall_score(y_test_bin, y_pred_bin),\n",
    "            'F1 Score': f1_score(y_test_bin, y_pred_bin),\n",
    "            'Matthews Correlation Coefficient': matthews_corrcoef(y_test_bin, y_pred_bin),\n",
    "            'Cohen Kappa': cohen_kappa_score(y_test_bin, y_pred_bin),\n",
    "            'True Positive Rate (TPR)': cm_metrics[class_label]['TPR'],\n",
    "            'True Negative Rate (TNR)': cm_metrics[class_label]['TNR'],\n",
    "            'False Positive Rate (FPR)': cm_metrics[class_label]['FPR'],\n",
    "            'False Negative Rate (FNR)': cm_metrics[class_label]['FNR'],\n",
    "            'Training Time (s)': train_time,\n",
    "            'Testing Time (s)': test_time\n",
    "        }\n",
    "        class_metrics_list.append(class_specific_metrics)\n",
    "    \n",
    "    # Append results for this fold\n",
    "    results.extend(class_metrics_list)\n",
    "    fold_idx += 1\n",
    "\n",
    "# Create DataFrames for results\n",
    "timing_df = pd.DataFrame(timing_results)\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV\n",
    "timing_df.to_csv(\"results/time.csv\", index=False)\n",
    "results_df.to_csv(\"results/metrics.csv\", index=False)\n",
    "\n",
    "# Plot feature importance\n",
    "if hasattr(rotation_forest, 'feature_importances_'):\n",
    "    feature_names = df.drop(columns=['label']).columns.tolist()\n",
    "    importances = rotation_forest.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title('Rotation Forest Feature Importances')\n",
    "    plt.bar(range(len(indices)), importances[indices], align='center')\n",
    "    plt.xticks(range(len(indices)), [feature_names[i] for i in indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualizations/feature_importance.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Generate a pair plot for the most important features\n",
    "feature_names = df.drop(columns=['label']).columns.tolist()\n",
    "\n",
    "# Create a correlation matrix for feature selection\n",
    "corr_matrix = pd.DataFrame(X, columns=feature_names).corrwith(pd.Series(y)).abs().sort_values(ascending=False)\n",
    "\n",
    "# Select top features\n",
    "if len(feature_names) > 4:\n",
    "    top_features = corr_matrix.nlargest(4).index.tolist()\n",
    "else:\n",
    "    top_features = feature_names\n",
    "\n",
    "top_features_df = df[top_features + ['label']].copy()\n",
    "top_features_df['label'] = label_encoder.inverse_transform(top_features_df['label'])\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(top_features_df, hue='label')\n",
    "plt.savefig(\"visualizations/pairplot.png\")\n",
    "plt.close()\n",
    "\n",
    "# Visualize the distribution of classes\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts = pd.Series(label_encoder.inverse_transform(y)).value_counts()\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visualizations/class_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Classification Metrics Across Folds:\")\n",
    "print(results_df.head())\n",
    "\n",
    "\n",
    "\n",
    "# Calculate and display average metrics across folds\n",
    "avg_metrics = results_df.groupby(['Classifier', 'Class']).mean().reset_index()\n",
    "avg_metrics.to_csv(\"results/avg_metrics.csv\", index=False)\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(avg_metrics[['Classifier', 'Class', 'Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
    "\n",
    "print(\"Rotation Forest implementation completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
