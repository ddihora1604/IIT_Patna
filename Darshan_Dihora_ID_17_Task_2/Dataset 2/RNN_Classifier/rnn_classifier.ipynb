{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Preprocessing data...\n",
      "Applying ADASYN/SMOTE to balance classes...\n",
      "Class distribution before resampling:\n",
      "Class 0: 2 samples\n",
      "Class 1: 1032 samples\n",
      "Class 2: 2 samples\n",
      "Class 3: 4 samples\n",
      "Class 4: 277 samples\n",
      "Class 5: 18 samples\n",
      "Class 6: 6767 samples\n",
      "Class 7: 463 samples\n",
      "Class 8: 3820 samples\n",
      "Class 9: 3828 samples\n",
      "Class 10: 3955 samples\n",
      "Class 11: 16 samples\n",
      "Class 12: 3371 samples\n",
      "Class 13: 4148 samples\n",
      "Class 14: 5031 samples\n",
      "Class 15: 293 samples\n",
      "Class 16: 158 samples\n",
      "Class 17: 9 samples\n",
      "Class 18: 57 samples\n",
      "Class 19: 1900 samples\n",
      "Class 20: 2429 samples\n",
      "Class 21: 3037 samples\n",
      "Class 22: 291 samples\n",
      "Class 23: 961 samples\n",
      "Class 24: 733 samples\n",
      "Class 25: 844 samples\n",
      "Class 26: 115 samples\n",
      "Class 27: 78 samples\n",
      "Class 28: 1 samples\n",
      "Class 29: 79 samples\n",
      "Class 30: 2 samples\n",
      "Class 31: 2 samples\n",
      "Class 32: 33 samples\n",
      "Class 33: 5 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ddihora1604\\AppData\\Local\\Temp\\ipykernel_2960\\3812942515.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some classes have fewer than 6 samples. Using SMOTE instead of ADASYN.\n",
      "Error during resampling: The 'k_neighbors' parameter of SMOTE must be an int in the range [1, inf) or an object implementing 'kneighbors' and 'kneighbors_graph'. Got 0 instead.\n",
      "Continuing with original imbalanced data.\n",
      "Training fold 1/2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4429 - loss: 2.1090 - val_accuracy: 0.7543 - val_loss: 0.6486\n",
      "Epoch 2/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7361 - loss: 0.6434 - val_accuracy: 0.7822 - val_loss: 0.5236\n",
      "Epoch 3/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7660 - loss: 0.5465 - val_accuracy: 0.7840 - val_loss: 0.4898\n",
      "Epoch 4/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7745 - loss: 0.5180 - val_accuracy: 0.7902 - val_loss: 0.4771\n",
      "Epoch 5/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7797 - loss: 0.5032 - val_accuracy: 0.7932 - val_loss: 0.4674\n",
      "Epoch 6/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7824 - loss: 0.4922 - val_accuracy: 0.7946 - val_loss: 0.4594\n",
      "Epoch 7/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7870 - loss: 0.4838 - val_accuracy: 0.7968 - val_loss: 0.4559\n",
      "Epoch 8/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7896 - loss: 0.4779 - val_accuracy: 0.7968 - val_loss: 0.4508\n",
      "Epoch 9/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7897 - loss: 0.4725 - val_accuracy: 0.8000 - val_loss: 0.4455\n",
      "Epoch 10/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7928 - loss: 0.4664 - val_accuracy: 0.8016 - val_loss: 0.4380\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training fold 2/2...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4501 - loss: 2.1061 - val_accuracy: 0.7519 - val_loss: 0.6373\n",
      "Epoch 2/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7492 - loss: 0.6080 - val_accuracy: 0.7779 - val_loss: 0.5293\n",
      "Epoch 3/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7685 - loss: 0.5328 - val_accuracy: 0.7809 - val_loss: 0.4975\n",
      "Epoch 4/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7769 - loss: 0.5065 - val_accuracy: 0.7900 - val_loss: 0.4805\n",
      "Epoch 5/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7820 - loss: 0.4941 - val_accuracy: 0.7960 - val_loss: 0.4718\n",
      "Epoch 6/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7841 - loss: 0.4841 - val_accuracy: 0.7969 - val_loss: 0.4661\n",
      "Epoch 7/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7920 - loss: 0.4732 - val_accuracy: 0.8008 - val_loss: 0.4565\n",
      "Epoch 8/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7910 - loss: 0.4691 - val_accuracy: 0.8003 - val_loss: 0.4533\n",
      "Epoch 9/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7962 - loss: 0.4611 - val_accuracy: 0.8161 - val_loss: 0.4445\n",
      "Epoch 10/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7975 - loss: 0.4529 - val_accuracy: 0.8195 - val_loss: 0.4407\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Metrics Across Folds:\n",
      "  Classifier  Fold  Class  Accuracy  Precision    Recall  F1 Score  \\\n",
      "0        RNN     1      0  0.999954   0.000000  0.000000  0.000000   \n",
      "1        RNN     1      1  0.987523   0.666232  0.967803  0.789189   \n",
      "2        RNN     1      2  0.999954   0.000000  0.000000  0.000000   \n",
      "3        RNN     1      3  0.999863   0.000000  0.000000  0.000000   \n",
      "4        RNN     1      4  0.999086   0.894366  0.962121  0.927007   \n",
      "\n",
      "   Matthews Correlation Coefficient  Cohen Kappa  True Positive Rate (TPR)  \\\n",
      "0                          0.000000     0.000000                  0.000000   \n",
      "1                          0.797511     0.782986                  0.967803   \n",
      "2                          0.000000     0.000000                  0.000000   \n",
      "3                          0.000000     0.000000                  0.000000   \n",
      "4                          0.927174     0.926548                  0.962121   \n",
      "\n",
      "   True Negative Rate (TNR)  False Positive Rate (FPR)  \\\n",
      "0                  1.000000                   0.000000   \n",
      "1                  0.988011                   0.011989   \n",
      "2                  1.000000                   0.000000   \n",
      "3                  1.000000                   0.000000   \n",
      "4                  0.999310                   0.000690   \n",
      "\n",
      "   False Negative Rate (FNR)  Training Time (s)  Testing Time (s)  \n",
      "0                   1.000000          15.024168          1.078961  \n",
      "1                   0.032197          15.024168          1.078961  \n",
      "2                   1.000000          15.024168          1.078961  \n",
      "3                   1.000000          15.024168          1.078961  \n",
      "4                   0.037879          15.024168          1.078961  \n",
      "\n",
      "Average Metrics Across Folds:\n",
      "   Classifier  Class  Accuracy  Precision    Recall  F1 Score\n",
      "0         RNN      0  0.999954   0.000000  0.000000  0.000000\n",
      "1         RNN      1  0.987112   0.651473  0.975965  0.781189\n",
      "2         RNN      2  0.999954   0.000000  0.000000  0.000000\n",
      "3         RNN      3  0.999909   0.000000  0.000000  0.000000\n",
      "4         RNN      4  0.998789   0.856274  0.977612  0.912102\n",
      "5         RNN      5  0.999589   0.000000  0.000000  0.000000\n",
      "6         RNN      6  0.999749   0.999851  0.998518  0.999184\n",
      "7         RNN      7  0.999520   0.984620  0.969759  0.977123\n",
      "8         RNN      8  0.999680   0.998942  0.997364  0.998152\n",
      "9         RNN      9  0.999817   0.999472  0.998444  0.998957\n",
      "10        RNN     10  0.954229   0.675865  0.948656  0.789318\n",
      "11        RNN     11  0.999634   0.000000  0.000000  0.000000\n",
      "12        RNN     12  0.966134   0.880584  0.661950  0.750640\n",
      "13        RNN     13  0.951509   0.699008  0.889956  0.777246\n",
      "14        RNN     14  0.950253   0.703011  0.982383  0.819489\n",
      "15        RNN     15  0.999520   0.945906  0.986302  0.965580\n",
      "16        RNN     16  0.995750   0.390625  0.130592  0.160283\n",
      "17        RNN     17  0.999794   0.000000  0.000000  0.000000\n",
      "18        RNN     18  0.998469   0.041667  0.021739  0.028571\n",
      "19        RNN     19  0.963209   0.622869  0.382060  0.459860\n",
      "20        RNN     20  0.951304   0.622031  0.312592  0.361689\n",
      "21        RNN     21  0.950001   0.912267  0.310277  0.462567\n",
      "22        RNN     22  0.993967   0.658414  0.252055  0.339519\n",
      "23        RNN     23  0.983433   0.570244  0.997921  0.725730\n",
      "24        RNN     24  0.983204   0.000000  0.000000  0.000000\n",
      "25        RNN     25  0.999703   0.989355  0.995256  0.992297\n",
      "26        RNN     26  0.997006   0.270833  0.243914  0.235525\n",
      "27        RNN     27  0.998126   0.000000  0.000000  0.000000\n",
      "28        RNN     28  0.999977   0.000000  0.000000  0.000000\n",
      "29        RNN     29  0.998195   0.000000  0.000000  0.000000\n",
      "30        RNN     30  0.999954   0.000000  0.000000  0.000000\n",
      "31        RNN     31  0.999954   0.000000  0.000000  0.000000\n",
      "32        RNN     32  0.999223   0.250000  0.321429  0.281250\n",
      "33        RNN     33  0.999886   0.000000  0.000000  0.000000\n",
      "RNN Classifier implementation completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             balanced_accuracy_score, confusion_matrix,\n",
    "                             matthews_corrcoef, cohen_kappa_score)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time\n",
    "import os\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Set the number of K folds\n",
    "K_FOLDS = 2\n",
    "\n",
    "# Create directories to save results\n",
    "os.makedirs(\"confusion_matrices\", exist_ok=True)\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Helper function for confusion matrix metrics\n",
    "def confusion_matrix_metrics(cm, classes):\n",
    "    metrics = {}\n",
    "    for idx, class_label in enumerate(classes):\n",
    "        TP = cm[idx, idx]  # True Positives for this class\n",
    "        FP = cm[:, idx].sum() - TP  # False Positives for this class\n",
    "        FN = cm[idx, :].sum() - TP  # False Negatives for this class\n",
    "        TN = cm.sum() - (TP + FP + FN)  # True Negatives for this class\n",
    "\n",
    "        metrics[class_label] = {\n",
    "            'TPR': TP / (TP + FN + 1e-10) if (TP + FN) > 0 else 0,\n",
    "            'TNR': TN / (TN + FP + 1e-10) if (TN + FP) > 0 else 0,\n",
    "            'FPR': FP / (FP + TN + 1e-10) if (FP + TN) > 0 else 0,\n",
    "            'FNR': FN / (FN + TP + 1e-10) if (FN + TP) > 0 else 0\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('C:/Users/ddihora1604/Downloads/IIT Patna/Darshan_Dihora_ID_17_Task_2/Dataset 2/part-00001_preprocessed_dataset.csv')\n",
    "\n",
    "# Take 20% of the data for faster processing (optional, comment out if you want to use full dataset)\n",
    "df = df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "# Rename the last column as 'label' if it's not already named that\n",
    "df.rename(columns={df.columns[-1]: 'label'}, inplace=True)\n",
    "\n",
    "# Preprocessing: Handle missing values\n",
    "print(\"Preprocessing data...\")\n",
    "# Replace NaN values with column means for numerical columns\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# For categorical columns, fill with mode\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col != 'label':  # Don't replace label\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical features if any\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col != 'label':  # Don't encode label yet\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Encode the label column\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Extract features and target\n",
    "X = df.drop(columns=['label']).values\n",
    "y = df['label'].values\n",
    "\n",
    "# Apply ADASYN SMOTE for handling imbalanced classes\n",
    "print(\"Applying ADASYN/SMOTE to balance classes...\")\n",
    "\n",
    "# Check class distribution before resampling\n",
    "print(\"Class distribution before resampling:\")\n",
    "for class_label, count in zip(*np.unique(y, return_counts=True)):\n",
    "    print(f\"Class {label_encoder.classes_[class_label]}: {count} samples\")\n",
    "\n",
    "# Visualize original class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts = pd.Series(y).value_counts().sort_index()\n",
    "ax = sns.barplot(x=[label_encoder.classes_[i] for i in class_counts.index], y=class_counts.values)\n",
    "plt.title('Class Distribution Before Resampling')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "for i, count in enumerate(class_counts.values):\n",
    "    ax.text(i, count + 5, str(count), ha='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visualizations/class_distribution_before_resampling.png\")\n",
    "plt.close()\n",
    "\n",
    "# Check if we have enough samples for ADASYN\n",
    "min_samples_needed = 6  # ADASYN default needs at least 6 samples per class\n",
    "class_counts = np.bincount(y.astype(int))\n",
    "\n",
    "# Use SMOTE if any class has fewer than required samples, else use ADASYN\n",
    "if np.any(class_counts < min_samples_needed):\n",
    "    print(\"Some classes have fewer than 6 samples. Using SMOTE instead of ADASYN.\")\n",
    "    sampler = SMOTE(random_state=42, k_neighbors=min(5, np.min(class_counts)-1))\n",
    "else:\n",
    "    print(\"Using ADASYN for oversampling.\")\n",
    "    sampler = ADASYN(random_state=42)\n",
    "\n",
    "try:\n",
    "    # Apply resampling before scaling to avoid data leakage\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "    \n",
    "    # Print and visualize class distribution after resampling\n",
    "    print(\"Class distribution after resampling:\")\n",
    "    for class_label, count in zip(*np.unique(y_resampled, return_counts=True)):\n",
    "        print(f\"Class {label_encoder.classes_[class_label]}: {count} samples\")\n",
    "    \n",
    "    # Update X and y with resampled data\n",
    "    X = X_resampled\n",
    "    y = y_resampled\n",
    "    \n",
    "    # Visualize resampled class distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    resampled_class_counts = pd.Series(y).value_counts().sort_index()\n",
    "    ax = sns.barplot(x=[label_encoder.classes_[i] for i in resampled_class_counts.index], \n",
    "                     y=resampled_class_counts.values)\n",
    "    plt.title('Class Distribution After Resampling')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    for i, count in enumerate(resampled_class_counts.values):\n",
    "        ax.text(i, count + 5, str(count), ha='center')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualizations/class_distribution_after_resampling.png\")\n",
    "    plt.close()\n",
    "except ValueError as e:\n",
    "    print(f\"Error during resampling: {e}\")\n",
    "    print(\"Continuing with original imbalanced data.\")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape input for RNN (samples, timesteps, features)\n",
    "# Treat each feature as a time step for simplicity\n",
    "X_reshaped = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "# Initialize to store results\n",
    "results = []\n",
    "timing_results = []\n",
    "\n",
    "# Create K-fold cross-validation\n",
    "kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Function to build the RNN model\n",
    "def build_rnn_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=input_shape, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Fold-wise training and evaluation\n",
    "fold_idx = 1\n",
    "for train_index, test_index in kf.split(X_reshaped):\n",
    "    print(f\"Training fold {fold_idx}/{K_FOLDS}...\")\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test = X_reshaped[train_index], X_reshaped[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Convert labels to one-hot encoding for RNN\n",
    "    y_train_onehot = to_categorical(y_train, num_classes=num_classes)\n",
    "    \n",
    "    # Build and train the model\n",
    "    rnn_model = build_rnn_model(input_shape=(X_train.shape[1], X_train.shape[2]), num_classes=num_classes)\n",
    "    \n",
    "    # Record start time\n",
    "    start_train_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    history = rnn_model.fit(\n",
    "        X_train, y_train_onehot,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    train_time = time.time() - start_train_time\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'RNN Accuracy - Fold {fold_idx}')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'RNN Loss - Fold {fold_idx}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"visualizations/training_history_fold_{fold_idx}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Make predictions\n",
    "    start_test_time = time.time()\n",
    "    y_pred_proba = rnn_model.predict(X_test)\n",
    "    test_time = time.time() - start_test_time\n",
    "    \n",
    "    # Convert probabilities to classes\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    \n",
    "    # Record timing results\n",
    "    timing_results.append({\n",
    "        'Classifier': 'RNN',\n",
    "        'Fold': fold_idx,\n",
    "        'Training Time (s)': train_time,\n",
    "        'Testing Time (s)': test_time,\n",
    "        'Total Time (s)': train_time + test_time\n",
    "    })\n",
    "    \n",
    "    # Compute metrics\n",
    "    unique_classes = np.unique(y)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=unique_classes)\n",
    "    cm_metrics = confusion_matrix_metrics(cm, unique_classes)\n",
    "    \n",
    "    # Plot and save confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=[class_names[i] if i < len(class_names) else i for i in unique_classes],\n",
    "                yticklabels=[class_names[i] if i < len(class_names) else i for i in unique_classes])\n",
    "    plt.title(f\"RNN - Fold {fold_idx} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.savefig(f\"confusion_matrices/fold_{fold_idx}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate metrics per class\n",
    "    class_metrics_list = []\n",
    "    for class_label in unique_classes:\n",
    "        # Create binary labels for this class\n",
    "        y_test_bin = (y_test == class_label).astype(int)\n",
    "        y_pred_bin = (y_pred == class_label).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        class_specific_metrics = {\n",
    "            'Classifier': 'RNN',\n",
    "            'Fold': fold_idx,\n",
    "            'Class': class_names[class_label] if class_label < len(class_names) else class_label,\n",
    "            'Accuracy': accuracy_score(y_test_bin, y_pred_bin),\n",
    "            'Precision': precision_score(y_test_bin, y_pred_bin, zero_division=0),\n",
    "            'Recall': recall_score(y_test_bin, y_pred_bin),\n",
    "            'F1 Score': f1_score(y_test_bin, y_pred_bin),\n",
    "            'Matthews Correlation Coefficient': matthews_corrcoef(y_test_bin, y_pred_bin),\n",
    "            'Cohen Kappa': cohen_kappa_score(y_test_bin, y_pred_bin),\n",
    "            'True Positive Rate (TPR)': cm_metrics[class_label]['TPR'],\n",
    "            'True Negative Rate (TNR)': cm_metrics[class_label]['TNR'],\n",
    "            'False Positive Rate (FPR)': cm_metrics[class_label]['FPR'],\n",
    "            'False Negative Rate (FNR)': cm_metrics[class_label]['FNR'],\n",
    "            'Training Time (s)': train_time,\n",
    "            'Testing Time (s)': test_time\n",
    "        }\n",
    "        class_metrics_list.append(class_specific_metrics)\n",
    "    \n",
    "    # Append results for this fold\n",
    "    results.extend(class_metrics_list)\n",
    "    fold_idx += 1\n",
    "\n",
    "# Create DataFrames for results\n",
    "timing_df = pd.DataFrame(timing_results)\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV\n",
    "timing_df.to_csv(\"results/time.csv\", index=False)\n",
    "results_df.to_csv(\"results/metrics.csv\", index=False)\n",
    "\n",
    "# Feature importance isn't directly available for RNNs, but we can try to visualize input-output correlations\n",
    "X_original = df.drop(columns=['label']).values  # Original features before reshaping\n",
    "feature_names = df.drop(columns=['label']).columns.tolist()\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = pd.DataFrame(X_original, columns=feature_names).corrwith(pd.Series(y)).sort_values(ascending=False)\n",
    "\n",
    "# Plot feature correlation with target\n",
    "plt.figure(figsize=(12, 8))\n",
    "corr_matrix.plot(kind='bar')\n",
    "plt.title('Feature Correlation with Target')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Correlation')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visualizations/feature_correlation.png\")\n",
    "plt.close()\n",
    "\n",
    "# Generate a pair plot for the most important features\n",
    "if len(feature_names) > 4:\n",
    "    top_features = corr_matrix.abs().nlargest(4).index.tolist()\n",
    "else:\n",
    "    top_features = feature_names\n",
    "\n",
    "top_features_df = df[top_features + ['label']].copy()\n",
    "top_features_df['label'] = label_encoder.inverse_transform(top_features_df['label'])\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(top_features_df, hue='label')\n",
    "plt.savefig(\"visualizations/pairplot.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Classification Metrics Across Folds:\")\n",
    "print(results_df.head())\n",
    "\n",
    "\n",
    "# Calculate and display average metrics across folds\n",
    "avg_metrics = results_df.groupby(['Classifier', 'Class']).mean().reset_index()\n",
    "avg_metrics.to_csv(\"results/avg_metrics.csv\", index=False)\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(avg_metrics[['Classifier', 'Class', 'Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
    "\n",
    "print(\"RNN Classifier implementation completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
