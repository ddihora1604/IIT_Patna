{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully with shape: (2392, 15)\n",
      "Sampled dataset shape: (478, 15)\n",
      "Performing Exploratory Data Analysis...\n",
      "EDA visualizations created successfully!\n",
      "Preprocessing data...\n",
      "Starting 2-fold cross-validation with Ridor-like Classifier...\n",
      "Processing fold 1/2...\n",
      "Applying ADASYN for class balancing in fold 1...\n",
      "Original training set shape: (239, 14), Resampled: (608, 14)\n",
      "Processing fold 2/2...\n",
      "Applying ADASYN for class balancing in fold 2...\n",
      "Original training set shape: (239, 14), Resampled: (572, 14)\n",
      "Classification Metrics Across Folds:\n",
      "   Classifier  Fold  Class  Accuracy  Precision    Recall  F1 Score  \\\n",
      "0  Ridor-like     1    0.0  0.941423   0.400000  0.333333  0.363636   \n",
      "1  Ridor-like     1    1.0  0.949791   0.928571  0.541667  0.684211   \n",
      "2  Ridor-like     1    2.0  0.882845   0.630769  0.911111  0.745455   \n",
      "3  Ridor-like     1    3.0  0.945607   0.829787  0.886364  0.857143   \n",
      "4  Ridor-like     1    4.0  0.945607   0.990291  0.894737  0.940092   \n",
      "\n",
      "   Balanced Accuracy  Matthews Correlation Coefficient  Cohen Kappa Score  \\\n",
      "0           0.653451                          0.334723           0.333200   \n",
      "1           0.768508                          0.687316           0.658977   \n",
      "2           0.893700                          0.691785           0.672603   \n",
      "3           0.922669                          0.824279           0.823596   \n",
      "4           0.943368                          0.894364           0.890518   \n",
      "\n",
      "   True Positive Rate (TPR)  True Negative Rate (TNR)  \\\n",
      "0                  0.333333                  0.973568   \n",
      "1                  0.541667                  0.995349   \n",
      "2                  0.911111                  0.876289   \n",
      "3                  0.886364                  0.958974   \n",
      "4                  0.894737                  0.992000   \n",
      "\n",
      "   False Positive Rate (FPR)  False Negative Rate (FNR)  Training Time (s)  \\\n",
      "0                   0.026432                   0.666667           0.026926   \n",
      "1                   0.004651                   0.458333           0.026926   \n",
      "2                   0.123711                   0.088889           0.026926   \n",
      "3                   0.041026                   0.113636           0.026926   \n",
      "4                   0.008000                   0.105263           0.026926   \n",
      "\n",
      "   Testing Time (s)  \n",
      "0               0.0  \n",
      "1               0.0  \n",
      "2               0.0  \n",
      "3               0.0  \n",
      "4               0.0  \n",
      "\n",
      "Average Metrics Across Folds:\n",
      "   Classifier  Class  Accuracy  Precision    Recall  F1 Score\n",
      "0  Ridor-like    0.0  0.960251   0.563636  0.566667  0.562771\n",
      "1  Ridor-like    1.0  0.951883   0.817227  0.750833  0.748885\n",
      "2  Ridor-like    2.0  0.907950   0.701748  0.880556  0.777489\n",
      "3  Ridor-like    3.0  0.953975   0.914894  0.836039  0.868571\n",
      "4  Ridor-like    4.0  0.962343   0.995146  0.926877  0.959586\n",
      "\n",
      "Ridor-like Classifier implementation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                           balanced_accuracy_score, confusion_matrix, \n",
    "                           matthews_corrcoef, cohen_kappa_score)\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Create directories for output\n",
    "os.makedirs(\"confusion_matrices\", exist_ok=True)\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"rules\", exist_ok=True)\n",
    "\n",
    "# Set the number of K folds\n",
    "K_FOLDS = 2\n",
    "\n",
    "# Helper function for confusion matrix metrics\n",
    "def confusion_matrix_metrics(cm, classes):\n",
    "    metrics = {}\n",
    "    for idx, class_label in enumerate(classes):\n",
    "        TP = cm[idx, idx]  # True Positives for this class\n",
    "        FP = cm[:, idx].sum() - TP  # False Positives for this class\n",
    "        FN = cm[idx, :].sum() - TP  # False Negatives for this class\n",
    "        TN = cm.sum() - (TP + FP + FN)  # True Negatives for this class\n",
    "\n",
    "        metrics[class_label] = {\n",
    "            'TPR': TP / (TP + FN + 1e-10) if (TP + FN) > 0 else 0,\n",
    "            'TNR': TN / (TN + FP + 1e-10) if (TN + FP) > 0 else 0,\n",
    "            'FPR': FP / (FP + TN + 1e-10) if (FP + TN) > 0 else 0,\n",
    "            'FNR': FN / (FN + TP + 1e-10) if (FN + TP) > 0 else 0\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "# Custom Ridor-like Classifier implementation using Decision Trees\n",
    "class RidorLikeClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, max_rules=6, min_samples_leaf=2, max_depth=4, random_state=42):\n",
    "        self.max_rules = max_rules\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.rules = {}\n",
    "        self.default_class = None\n",
    "        self.classes_ = None\n",
    "        self.rule_trees = []\n",
    "        self.rule_texts = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Store classes\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        # Find the majority class (default class)\n",
    "        counts = np.bincount(y) if np.issubdtype(y.dtype, np.integer) else np.bincount([np.where(self.classes_ == c)[0][0] for c in y])\n",
    "        self.default_class = np.argmax(counts)\n",
    "        \n",
    "        # For each class (except default), create exception rules\n",
    "        X_curr = X.copy()\n",
    "        y_curr = y.copy()\n",
    "        \n",
    "        # Keep track of which samples are covered by rules\n",
    "        covered_indices = np.zeros(len(y), dtype=bool)\n",
    "        \n",
    "        for class_idx, class_label in enumerate(self.classes_):\n",
    "            if class_idx == self.default_class:\n",
    "                continue\n",
    "                \n",
    "            # Create binary classification problem for this class vs. others\n",
    "            y_binary = np.where(y_curr == class_label, 1, 0)\n",
    "            \n",
    "            # If enough samples of this class remain\n",
    "            if np.sum(y_binary) >= self.min_samples_leaf:\n",
    "                # Create a decision tree to find rules\n",
    "                tree = DecisionTreeClassifier(\n",
    "                    max_depth=self.max_depth,\n",
    "                    min_samples_leaf=self.min_samples_leaf,\n",
    "                    random_state=self.random_state\n",
    "                )\n",
    "                \n",
    "                tree.fit(X_curr, y_binary)\n",
    "                self.rule_trees.append((class_label, tree))\n",
    "                \n",
    "                # Generate human-readable rules for this class\n",
    "                rule_text = f\"Class {class_label}:\\n\"\n",
    "                rule_text += self._extract_rules_from_tree(tree, X.columns if hasattr(X, 'columns') else range(X.shape[1]))\n",
    "                self.rule_texts.append(rule_text)\n",
    "                \n",
    "                # Find samples covered by these rules\n",
    "                predictions = tree.predict(X_curr)\n",
    "                newly_covered = np.where((predictions == 1) & (y_binary == 1))[0]\n",
    "                \n",
    "                # Mark these samples as covered\n",
    "                if len(newly_covered) > 0:\n",
    "                    covered_indices[newly_covered] = True\n",
    "        \n",
    "        # Save final rule set\n",
    "        for idx, rule_text in enumerate(self.rule_texts):\n",
    "            with open(f\"rules/ridor_like_rules_{idx}.txt\", \"w\") as f:\n",
    "                f.write(rule_text)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _extract_rules_from_tree(self, tree, feature_names):\n",
    "        \"\"\"Extract human-readable rules from a decision tree\"\"\"\n",
    "        tree_ = tree.tree_\n",
    "        feature_name = [\n",
    "            feature_names[i] if i != -2 else \"undefined!\"\n",
    "            for i in tree_.feature\n",
    "        ]\n",
    "        \n",
    "        rules = []\n",
    "        \n",
    "        def recurse(node, depth, path):\n",
    "            if tree_.feature[node] != -2:  # Not a leaf\n",
    "                name = feature_name[node]\n",
    "                threshold = tree_.threshold[node]\n",
    "                \n",
    "                # Left branch (<=)\n",
    "                recurse(tree_.children_left[node], depth + 1, \n",
    "                        path + [f\"{name} <= {threshold:.4f}\"])\n",
    "                \n",
    "                # Right branch (>)\n",
    "                recurse(tree_.children_right[node], depth + 1,\n",
    "                        path + [f\"{name} > {threshold:.4f}\"])\n",
    "            else:  # Leaf node\n",
    "                if tree_.value[node][0][1] > tree_.value[node][0][0]:  # More positive than negative\n",
    "                    coverage = f\"{int(tree_.value[node][0][1])}/{int(tree_.value[node][0].sum())}\"\n",
    "                    rule = \"  IF \" + \" AND \".join(path) + f\" THEN class ({coverage})\"\n",
    "                    rules.append(rule)\n",
    "        \n",
    "        recurse(0, 1, [])\n",
    "        return \"\\n\".join(rules) + \"\\n\"\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class for X.\"\"\"\n",
    "        if not hasattr(self, 'rule_trees') or len(self.rule_trees) == 0:\n",
    "            return np.full(X.shape[0], self.default_class)\n",
    "        \n",
    "        # Initialize with default class\n",
    "        predictions = np.full(X.shape[0], self.classes_[self.default_class])\n",
    "        \n",
    "        # Apply rules in order\n",
    "        for class_label, tree in self.rule_trees:\n",
    "            # Predict which samples match this rule\n",
    "            rule_predictions = tree.predict(X)\n",
    "            \n",
    "            # Update predictions where rule applies\n",
    "            mask = (rule_predictions == 1)\n",
    "            predictions[mask] = class_label\n",
    "            \n",
    "        return predictions\n",
    "\n",
    "# Function for exploratory data analysis\n",
    "def perform_eda(df):\n",
    "    print(\"Performing Exploratory Data Analysis...\")\n",
    "      \n",
    "    \n",
    "    \n",
    "    # 1. Create histograms for numeric features\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        # Create histograms for each numeric feature\n",
    "        df[numeric_cols].hist(figsize=(15, 15), bins=20, layout=(5, 5))\n",
    "        plt.suptitle('Histograms of Numeric Features', y=0.92)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"visualizations/histograms.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    # 2. Create boxplots to visualize the distribution by class\n",
    "    fig, axes = plt.subplots(nrows=len(numeric_cols[:5]), figsize=(12, 15))\n",
    "    for i, feature in enumerate(numeric_cols[:5]):  # Limit to first 5 features for clarity\n",
    "        sns.boxplot(x='label', y=feature, data=df, ax=axes[i])\n",
    "        axes[i].set_title(f'Distribution of {feature} by Class')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualizations/box_plots_by_class.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Create pair plot for visualizing relationships between features\n",
    "    \n",
    "    # Select a subset of numeric columns (first 5) to avoid overloading the pair plot\n",
    "    plot_columns = list(numeric_cols[:5])\n",
    "    # Add the target variable to the plot\n",
    "    plot_columns.append('label')\n",
    "    # Create the pair plot\n",
    "    pair_plot = sns.pairplot(df[plot_columns], hue='label', diag_kind='kde', \n",
    "                          plot_kws={'alpha': 0.6, 's': 30, 'edgecolor': 'k', 'linewidth': 0.2})\n",
    "    pair_plot.fig.suptitle('Pair Plot of Features by Class', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualizations/pair_plot.png\")\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "    # 4. Create violin plots for distribution comparison\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    for i, feature in enumerate(numeric_cols[:4]):  # First 4 numeric features\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        sns.violinplot(x='label', y=feature, data=df)\n",
    "        plt.title(f'Violin Plot of {feature} by Class')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualizations/violin_plots.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"EDA visualizations created successfully!\")\n",
    "    return df  # Return potentially modified dataframe\n",
    "\n",
    "\n",
    "# Main processing function\n",
    "def main():\n",
    "    # Load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        df = pd.read_csv('C:/Users/ddihora1604/Downloads/IIT Patna/Darshan_Dihora_ID_17_Task_2/Dataset 1/Student_performance_data.csv')\n",
    "        print(f\"Dataset loaded successfully with shape: {df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Take 20% of the data for faster processing (if needed)\n",
    "    df = df.sample(frac=0.2, random_state=42)\n",
    "    print(f\"Sampled dataset shape: {df.shape}\")\n",
    "    \n",
    "    # Rename the last column as 'label' if not already named\n",
    "    df.rename(columns={df.columns[-1]: 'label'}, inplace=True)\n",
    "    \n",
    "    # Add EDA step here\n",
    "    df = perform_eda(df)\n",
    "    \n",
    "    # Data preprocessing\n",
    "    print(\"Preprocessing data...\")\n",
    "    \n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X = df.drop(columns=['label'])\n",
    "    y = df['label'].values\n",
    "    X_columns = X.columns\n",
    "    X = pd.DataFrame(imputer.fit_transform(X), columns=X_columns)\n",
    "\n",
    "    # Add visualization of class distribution before balancing\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    class_counts_before = pd.Series(y).value_counts().sort_index()\n",
    "    ax = sns.barplot(x=class_counts_before.index, y=class_counts_before.values)\n",
    "    plt.title(\"Class Distribution Before ADASYN\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    for i, v in enumerate(class_counts_before.values):\n",
    "        ax.text(i, v + 5, str(v), ha='center')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualizations/class_distribution_before_adasyn.png\")\n",
    "    plt.close()\n",
    "        \n",
    "    # Initialize results storage\n",
    "    results = []\n",
    "    timing_results = []\n",
    "    rules_list = []\n",
    "    \n",
    "    # Set up KFold cross-validation\n",
    "    kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Cross-validation process\n",
    "    print(f\"Starting {K_FOLDS}-fold cross-validation with Ridor-like Classifier...\")\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        print(f\"Processing fold {fold_idx}/{K_FOLDS}...\")\n",
    "        \n",
    "        # Split the data for this fold\n",
    "        X_train, X_test = X.iloc[train_index].reset_index(drop=True), X.iloc[test_index].reset_index(drop=True)\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Apply ADASYN SMOTE to balance classes in the training set\n",
    "        print(f\"Applying ADASYN for class balancing in fold {fold_idx}...\")\n",
    "        try:\n",
    "            adasyn = ADASYN(random_state=42, n_neighbors=5)\n",
    "            X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
    "            \n",
    "            # Visualize class distribution after ADASYN\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            class_counts_after = pd.Series(y_train_resampled).value_counts().sort_index()\n",
    "            ax = sns.barplot(x=class_counts_after.index, y=class_counts_after.values)\n",
    "            plt.title(f\"Class Distribution After ADASYN (Fold {fold_idx})\")\n",
    "            plt.xlabel(\"Class\")\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.xticks(rotation=45)\n",
    "            for i, v in enumerate(class_counts_after.values):\n",
    "                ax.text(i, v + 5, str(v), ha='center')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"visualizations/class_distribution_after_adasyn_fold_{fold_idx}.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"Original training set shape: {X_train.shape}, Resampled: {X_train_resampled.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"ADASYN error: {e}. Using original imbalanced data.\")\n",
    "            X_train_resampled, y_train_resampled = X_train, y_train\n",
    "        \n",
    "        # Train Ridor-like classifier with balanced data\n",
    "        ridor = RidorLikeClassifier(\n",
    "            max_rules=6,\n",
    "            min_samples_leaf=2,\n",
    "            max_depth=4,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Record training time\n",
    "        start_train_time = time.time()\n",
    "        ridor.fit(X_train_resampled, y_train_resampled)  # Use resampled data here\n",
    "        train_time = time.time() - start_train_time\n",
    "        \n",
    "        # Get the rules as text\n",
    "        rules_text = \"\\n\".join(ridor.rule_texts)\n",
    "        rules_list.append({\"Fold\": fold_idx, \"Rules\": rules_text})\n",
    "        \n",
    "        # Save rules to file\n",
    "        with open(f\"rules/fold_{fold_idx}.txt\", \"w\") as f:\n",
    "            f.write(rules_text)\n",
    "        \n",
    "        # Record prediction time\n",
    "        start_test_time = time.time()\n",
    "        y_pred = ridor.predict(X_test)\n",
    "        test_time = time.time() - start_test_time\n",
    "        \n",
    "        # Record timing info\n",
    "        timing_results.append({\n",
    "            'Classifier': 'Ridor-like',\n",
    "            'Fold': fold_idx,\n",
    "            'Training Time (s)': train_time,\n",
    "            'Testing Time (s)': test_time,\n",
    "            'Total Time (s)': train_time + test_time\n",
    "        })\n",
    "        \n",
    "        # Get unique classes\n",
    "        unique_classes = np.unique(np.concatenate([y_test, y_pred]))\n",
    "        \n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=unique_classes)\n",
    "        cm_metrics = confusion_matrix_metrics(cm, unique_classes)\n",
    "        \n",
    "        # Calculate metrics for each class\n",
    "        for class_label in unique_classes:\n",
    "            # Binary classification metrics for this class\n",
    "            y_test_binary = np.array([1 if y == class_label else 0 for y in y_test])\n",
    "            y_pred_binary = np.array([1 if y == class_label else 0 for y in y_pred])\n",
    "            \n",
    "            # Calculate metrics\n",
    "            class_metrics = {\n",
    "                'Classifier': 'Ridor-like',\n",
    "                'Fold': fold_idx,\n",
    "                'Class': class_label,\n",
    "                'Accuracy': accuracy_score(y_test_binary, y_pred_binary),\n",
    "                'Precision': precision_score(y_test_binary, y_pred_binary, zero_division=0),\n",
    "                'Recall': recall_score(y_test_binary, y_pred_binary),\n",
    "                'F1 Score': f1_score(y_test_binary, y_pred_binary),\n",
    "                'Balanced Accuracy': balanced_accuracy_score(y_test_binary, y_pred_binary),\n",
    "                'Matthews Correlation Coefficient': matthews_corrcoef(y_test_binary, y_pred_binary),\n",
    "                'Cohen Kappa Score': cohen_kappa_score(y_test_binary, y_pred_binary),\n",
    "                'True Positive Rate (TPR)': cm_metrics[class_label]['TPR'],\n",
    "                'True Negative Rate (TNR)': cm_metrics[class_label]['TNR'],\n",
    "                'False Positive Rate (FPR)': cm_metrics[class_label]['FPR'],\n",
    "                'False Negative Rate (FNR)': cm_metrics[class_label]['FNR'],\n",
    "                'Training Time (s)': train_time,\n",
    "                'Testing Time (s)': test_time\n",
    "            }\n",
    "            \n",
    "            results.append(class_metrics)\n",
    "        \n",
    "        # Plot and save confusion matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=unique_classes, yticklabels=unique_classes)\n",
    "        plt.title(f\"Ridor-like Classifier - Fold {fold_idx} Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"confusion_matrices/fold_{fold_idx}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # # Visualize class distribution in test set\n",
    "        # plt.figure(figsize=(10, 6))\n",
    "        # class_counts = pd.Series(y_test).value_counts().sort_index()\n",
    "        # sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "        # plt.title(f\"Class Distribution in Test Set (Fold {fold_idx})\")\n",
    "        # plt.xlabel(\"Class\")\n",
    "        # plt.ylabel(\"Count\")\n",
    "        # plt.xticks(rotation=45)\n",
    "        # plt.tight_layout()\n",
    "        # plt.savefig(f\"visualizations/class_distribution_fold_{fold_idx}.png\")\n",
    "        # plt.close()\n",
    "        \n",
    "        # Feature importance for this fold's model\n",
    "        if hasattr(ridor, 'rule_trees') and len(ridor.rule_trees) > 0:\n",
    "            # Collect feature importance from all trees\n",
    "            feature_importance = np.zeros(len(X_columns))\n",
    "            for _, tree in ridor.rule_trees:\n",
    "                if hasattr(tree, 'feature_importances_'):\n",
    "                    feature_importance += tree.feature_importances_\n",
    "            \n",
    "            if np.sum(feature_importance) > 0:\n",
    "                # Normalize\n",
    "                feature_importance = feature_importance / len(ridor.rule_trees)\n",
    "                \n",
    "                # Create feature importance plot\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                importance_df = pd.DataFrame({\n",
    "                    'Feature': X_columns,\n",
    "                    'Importance': feature_importance\n",
    "                }).sort_values('Importance', ascending=False)\n",
    "                \n",
    "                sns.barplot(x='Importance', y='Feature', data=importance_df[:15])  # Top 15 features\n",
    "                plt.title(f'Feature Importance (Fold {fold_idx})')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"visualizations/feature_importance_fold_{fold_idx}.png\")\n",
    "                plt.close()\n",
    "    \n",
    "    # Create DataFrames for results and save to CSV\n",
    "    timing_df = pd.DataFrame(timing_results)\n",
    "    timing_df.to_csv(\"results/timing.csv\", index=False)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"Classification Metrics Across Folds:\")\n",
    "    print(results_df.head())\n",
    "    \n",
    "    # Save results to CSV\n",
    "    results_df.to_csv(\"results/metrics.csv\", index=False)\n",
    "    \n",
    "    # Save rules to CSV\n",
    "    rules_df = pd.DataFrame(rules_list)\n",
    "    rules_df.to_csv(\"results/rules.csv\", index=False)\n",
    "    \n",
    "    # Calculate and display average metrics across folds\n",
    "    avg_metrics = results_df.groupby(['Classifier', 'Class']).mean().reset_index()\n",
    "    avg_metrics.to_csv(\"results/avg_metrics.csv\", index=False)\n",
    "    print(\"\\nAverage Metrics Across Folds:\")\n",
    "    print(avg_metrics[['Classifier', 'Class', 'Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
    "    \n",
    "    \n",
    "    print(\"\\nRidor-like Classifier implementation completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
