{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully with shape: (2392, 15)\n",
      "Sampled dataset shape: (478, 15)\n",
      "Preprocessing data...\n",
      "Starting 2-fold cross-validation with Ridge Classifier...\n",
      "Processing fold 1/2...\n",
      "Applying ADASYN oversampling technique...\n",
      "Class distribution before ADASYN: 4.0    122\n",
      "3.0     42\n",
      "2.0     40\n",
      "1.0     25\n",
      "0.0     10\n",
      "Name: count, dtype: int64\n",
      "Class distribution after ADASYN: 2.0    129\n",
      "3.0    127\n",
      "0.0    123\n",
      "4.0    122\n",
      "1.0    114\n",
      "Name: count, dtype: int64\n",
      "Processing fold 2/2...\n",
      "Applying ADASYN oversampling technique...\n",
      "Class distribution before ADASYN: 4.0    114\n",
      "2.0     45\n",
      "3.0     44\n",
      "1.0     24\n",
      "0.0     12\n",
      "Name: count, dtype: int64\n",
      "Class distribution after ADASYN: 0.0    118\n",
      "4.0    114\n",
      "1.0    111\n",
      "2.0    110\n",
      "3.0    109\n",
      "Name: count, dtype: int64\n",
      "Classification Metrics Across Folds:\n",
      "        Classifier  Fold  Class  Accuracy  Precision    Recall  F1 Score  \\\n",
      "0  RidgeClassifier     1    0.0  0.849372   0.200000  0.666667  0.307692   \n",
      "1  RidgeClassifier     1    1.0  0.836820   0.272727  0.375000  0.315789   \n",
      "2  RidgeClassifier     1    2.0  0.803347   0.464286  0.288889  0.356164   \n",
      "3  RidgeClassifier     1    3.0  0.774059   0.250000  0.113636  0.156250   \n",
      "4  RidgeClassifier     1    4.0  0.841004   0.822034  0.850877  0.836207   \n",
      "\n",
      "   Balanced Accuracy  Matthews Correlation Coefficient  Cohen Kappa Score  \\\n",
      "0           0.762849                          0.307527           0.249738   \n",
      "1           0.631686                          0.229458           0.225766   \n",
      "2           0.605785                          0.257181           0.247471   \n",
      "3           0.518357                          0.051384           0.046543   \n",
      "4           0.841439                          0.682207           0.681825   \n",
      "\n",
      "   True Positive Rate (TPR)  True Negative Rate (TNR)  \\\n",
      "0                  0.666667                  0.859031   \n",
      "1                  0.375000                  0.888372   \n",
      "2                  0.288889                  0.922680   \n",
      "3                  0.113636                  0.923077   \n",
      "4                  0.850877                  0.832000   \n",
      "\n",
      "   False Positive Rate (FPR)  False Negative Rate (FNR)  Training Time (s)  \\\n",
      "0                   0.140969                   0.333333            0.00335   \n",
      "1                   0.111628                   0.625000            0.00335   \n",
      "2                   0.077320                   0.711111            0.00335   \n",
      "3                   0.076923                   0.886364            0.00335   \n",
      "4                   0.168000                   0.149123            0.00335   \n",
      "\n",
      "   Testing Time (s)  \n",
      "0          0.003507  \n",
      "1          0.003507  \n",
      "2          0.003507  \n",
      "3          0.003507  \n",
      "4          0.003507  \n",
      "\n",
      "Average Metrics Across Folds:\n",
      "        Classifier  Class  Accuracy  Precision    Recall  F1 Score\n",
      "0  RidgeClassifier    0.0  0.864017   0.186207  0.583333  0.282051\n",
      "1  RidgeClassifier    1.0  0.845188   0.323864  0.487500  0.388664\n",
      "2  RidgeClassifier    2.0  0.792887   0.332143  0.194444  0.244749\n",
      "3  RidgeClassifier    3.0  0.797071   0.358333  0.140152  0.200932\n",
      "4  RidgeClassifier    4.0  0.851464   0.825832  0.884455  0.853901\n",
      "\n",
      "Ridge Classifier implementation completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                            balanced_accuracy_score, confusion_matrix,\n",
    "                            matthews_corrcoef, cohen_kappa_score)\n",
    "from sklearn.impute import SimpleImputer\n",
    "import time\n",
    "import os\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Create directory for visualizations\n",
    "os.makedirs(\"confusion_matrices\", exist_ok=True)\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Set the number of K folds\n",
    "K_FOLDS = 2\n",
    "\n",
    "# Helper function for confusion matrix metrics\n",
    "def confusion_matrix_metrics(cm, classes):\n",
    "    metrics = {}\n",
    "    for idx, class_label in enumerate(classes):\n",
    "        TP = cm[idx, idx]  # True Positives for this class\n",
    "        FP = cm[:, idx].sum() - TP  # False Positives for this class\n",
    "        FN = cm[idx, :].sum() - TP  # False Negatives for this class\n",
    "        TN = cm.sum() - (TP + FP + FN)  # True Negatives for this class\n",
    "\n",
    "        metrics[class_label] = {\n",
    "            'TPR': TP / (TP + FN + 1e-10) if (TP + FN) > 0 else 0,\n",
    "            'TNR': TN / (TN + FP + 1e-10) if (TN + FP) > 0 else 0,\n",
    "            'FPR': FP / (FP + TN + 1e-10) if (FP + TN) > 0 else 0,\n",
    "            'FNR': FN / (FN + TP + 1e-10) if (FN + TP) > 0 else 0\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "try:\n",
    "    df = pd.read_csv('C:/Users/ddihora1604/Downloads/IIT Patna/Darshan_Dihora_ID_17_Task_2/Dataset 1/Student_performance_data.csv')\n",
    "    print(f\"Dataset loaded successfully with shape: {df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Take 20% of the data for faster processing (if needed)\n",
    "df = df.sample(frac=0.2, random_state=42)\n",
    "print(f\"Sampled dataset shape: {df.shape}\")\n",
    "\n",
    "# Rename the last column as 'label' if not already named\n",
    "df.rename(columns={df.columns[-1]: 'label'}, inplace=True)\n",
    "\n",
    "# Data preprocessing\n",
    "print(\"Preprocessing data...\")\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = df.drop(columns=['label'])\n",
    "X_columns = X.columns\n",
    "X = imputer.fit_transform(X)\n",
    "y = df['label'].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize results storage\n",
    "results = []\n",
    "timing_results = []\n",
    "\n",
    "# Set up KFold cross-validation\n",
    "kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Ridge classifier with hyperparameters (removed deprecated 'normalize' parameter)\n",
    "ridge_classifier = RidgeClassifier(\n",
    "    alpha=1.0,  # Regularization strength\n",
    "    fit_intercept=True,\n",
    "    copy_X=True,\n",
    "    max_iter=1000,\n",
    "    tol=0.001,\n",
    "    class_weight=None,\n",
    "    solver='auto',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Cross-validation process\n",
    "print(f\"Starting {K_FOLDS}-fold cross-validation with Ridge Classifier...\")\n",
    "fold_idx = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(f\"Processing fold {fold_idx}/{K_FOLDS}...\")\n",
    "    \n",
    "    # Split the data for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Apply ADASYN for handling class imbalance\n",
    "    print(f\"Applying ADASYN oversampling technique...\")\n",
    "    adasyn = ADASYN(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Print class distribution before and after ADASYN\n",
    "    train_class_dist_before = pd.Series(y_train).value_counts()\n",
    "    train_class_dist_after = pd.Series(y_train_resampled).value_counts()\n",
    "    print(f\"Class distribution before ADASYN: {train_class_dist_before}\")\n",
    "    print(f\"Class distribution after ADASYN: {train_class_dist_after}\")\n",
    "    \n",
    "    # Record training time\n",
    "    start_train_time = time.time()\n",
    "    ridge_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "    train_time = time.time() - start_train_time\n",
    "\n",
    "    # Record prediction time\n",
    "    start_test_time = time.time()\n",
    "    y_pred = ridge_classifier.predict(X_test)\n",
    "    test_time = time.time() - start_test_time\n",
    "\n",
    "    # Record timing info\n",
    "    timing_results.append({\n",
    "        'Classifier': 'RidgeClassifier',\n",
    "        'Fold': fold_idx,\n",
    "        'Training Time (s)': train_time,\n",
    "        'Testing Time (s)': test_time,\n",
    "        'Total Time (s)': train_time + test_time\n",
    "})\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    unique_classes = np.unique(y)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=unique_classes)\n",
    "    cm_metrics = confusion_matrix_metrics(cm, unique_classes)\n",
    "    \n",
    "    # Calculate metrics for each class\n",
    "    for class_label in unique_classes:\n",
    "        # Binary classification metrics for this class\n",
    "        y_test_binary = (y_test == class_label).astype(int)\n",
    "        y_pred_binary = (y_pred == class_label).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        class_metrics = {\n",
    "            'Classifier': 'RidgeClassifier',\n",
    "            'Fold': fold_idx,\n",
    "            'Class': class_label,\n",
    "            'Accuracy': accuracy_score(y_test_binary, y_pred_binary),\n",
    "            'Precision': precision_score(y_test_binary, y_pred_binary, zero_division=0),\n",
    "            'Recall': recall_score(y_test_binary, y_pred_binary),\n",
    "            'F1 Score': f1_score(y_test_binary, y_pred_binary),\n",
    "            'Balanced Accuracy': balanced_accuracy_score(y_test_binary, y_pred_binary),\n",
    "            'Matthews Correlation Coefficient': matthews_corrcoef(y_test_binary, y_pred_binary),\n",
    "            'Cohen Kappa Score': cohen_kappa_score(y_test_binary, y_pred_binary),\n",
    "            'True Positive Rate (TPR)': cm_metrics[class_label]['TPR'],\n",
    "            'True Negative Rate (TNR)': cm_metrics[class_label]['TNR'],\n",
    "            'False Positive Rate (FPR)': cm_metrics[class_label]['FPR'],\n",
    "            'False Negative Rate (FNR)': cm_metrics[class_label]['FNR'],\n",
    "            'Training Time (s)': train_time,\n",
    "            'Testing Time (s)': test_time\n",
    "        }\n",
    "        \n",
    "        results.append(class_metrics)\n",
    "    \n",
    "    # Plot and save confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=unique_classes, yticklabels=unique_classes)\n",
    "    plt.title(f\"Ridge Classifier - Fold {fold_idx} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"confusion_matrices/fold_{fold_idx}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Feature importance visualization (coefficients of Ridge Classifier)\n",
    "    if fold_idx == 1:  # Only for the first fold to avoid redundancy\n",
    "        coef = ridge_classifier.coef_\n",
    "        # For multiclass, average the absolute coefficients across classes\n",
    "        if coef.ndim > 1:\n",
    "            importance = np.mean(np.abs(coef), axis=0)\n",
    "        else:\n",
    "            importance = np.abs(coef)\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': X_columns,\n",
    "            'Importance': importance\n",
    "        })\n",
    "        feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "        \n",
    "        # Plot top 20 features or all if less than 20\n",
    "        top_n = min(20, len(feature_importance))\n",
    "        sns.barplot(x='Importance', y='Feature', data=feature_importance.head(top_n))\n",
    "        plt.title('Ridge Classifier Feature Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"visualizations/feature_importance.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    # Pair plot for the first 5 features and target\n",
    "    if fold_idx == 1:  # Only for the first fold\n",
    "        # Convert numpy array back to DataFrame for visualization\n",
    "        sample_size = min(1000, X_test.shape[0])  # Limit sample size for visualization\n",
    "        vis_df = pd.DataFrame(X_test[:sample_size], columns=X_columns)\n",
    "        vis_df['label'] = y_test[:sample_size]\n",
    "        \n",
    "        # Select first 5 features (or less if fewer features exist)\n",
    "        plot_features = list(X_columns[:min(5, len(X_columns))])\n",
    "        plot_features.append('label')\n",
    "        \n",
    "        # Create pair plot\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        pair_plot = sns.pairplot(vis_df[plot_features], hue='label', height=2.5)\n",
    "        plt.suptitle('Pair Plot of Top Features by Ridge Classifier', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        pair_plot.savefig(\"visualizations/pair_plot.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    fold_idx += 1\n",
    "\n",
    "# Create DataFrames for results and save to CSV\n",
    "timing_df = pd.DataFrame(timing_results)\n",
    "timing_df.to_csv(\"results/timing.csv\", index=False)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Classification Metrics Across Folds:\")\n",
    "print(results_df.head())\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv(\"results/metrics.csv\", index=False)\n",
    "\n",
    "# Calculate and display average metrics across folds\n",
    "avg_metrics = results_df.groupby(['Classifier', 'Class']).mean().reset_index()\n",
    "avg_metrics.to_csv(\"results/avg_metrics.csv\", index=False)\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(avg_metrics[['Classifier', 'Class', 'Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
    "\n",
    "print(\"\\nRidge Classifier implementation completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
