{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Original class distribution:\n",
      "label\n",
      "4.0    236\n",
      "3.0     86\n",
      "2.0     85\n",
      "1.0     49\n",
      "0.0     22\n",
      "Name: count, dtype: int64\n",
      "Preprocessing data...\n",
      "Training fold 1/2...\n",
      "Training fold 2/2...\n",
      "Classification Metrics Across Folds:\n",
      "  Classifier  Fold  Class  Accuracy  Precision    Recall  F1 Score  \\\n",
      "0   RUSBoost     1    0.0  0.953975   0.526316  0.833333  0.645161   \n",
      "1   RUSBoost     1    1.0  0.945607   0.789474  0.625000  0.697674   \n",
      "2   RUSBoost     1    2.0  0.979079   1.000000  0.888889  0.941176   \n",
      "3   RUSBoost     1    3.0  0.941423   0.788462  0.931818  0.854167   \n",
      "4   RUSBoost     1    4.0  0.962343   0.981651  0.938596  0.959641   \n",
      "\n",
      "   Matthews Correlation Coefficient  Cohen Kappa  True Positive Rate (TPR)  \\\n",
      "0                          0.640714     0.621890                  0.833333   \n",
      "1                          0.673740     0.668233                  0.625000   \n",
      "2                          0.930889     0.928507                  0.888889   \n",
      "3                          0.822303     0.817835                  0.931818   \n",
      "4                          0.925197     0.924380                  0.938596   \n",
      "\n",
      "   True Negative Rate (TNR)  False Positive Rate (FPR)  \\\n",
      "0                  0.960352                   0.039648   \n",
      "1                  0.981395                   0.018605   \n",
      "2                  1.000000                   0.000000   \n",
      "3                  0.943590                   0.056410   \n",
      "4                  0.984000                   0.016000   \n",
      "\n",
      "   False Negative Rate (FNR)  Training Time (s)  Testing Time (s)  \n",
      "0                   0.166667           0.215822          0.015461  \n",
      "1                   0.375000           0.215822          0.015461  \n",
      "2                   0.111111           0.215822          0.015461  \n",
      "3                   0.068182           0.215822          0.015461  \n",
      "4                   0.061404           0.215822          0.015461  \n",
      "\n",
      "Average Metrics Across Folds:\n",
      "  Classifier  Class  Accuracy  Precision    Recall  F1 Score\n",
      "0   RUSBoost    0.0  0.958159   0.532389  0.766667  0.626928\n",
      "1   RUSBoost    1.0  0.960251   0.797963  0.812500  0.795266\n",
      "2   RUSBoost    2.0  0.964435   0.925000  0.869444  0.895588\n",
      "3   RUSBoost    3.0  0.941423   0.819231  0.870671  0.841717\n",
      "4   RUSBoost    4.0  0.958159   0.982130  0.932413  0.956614\n",
      "RUSBoost implementation completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             balanced_accuracy_score, confusion_matrix,\n",
    "                             matthews_corrcoef, cohen_kappa_score)\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the number of K folds\n",
    "K_FOLDS = 2\n",
    "\n",
    "# Create directories to save results\n",
    "os.makedirs(\"confusion_matrices\", exist_ok=True)\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Helper function for confusion matrix metrics\n",
    "def confusion_matrix_metrics(cm, classes):\n",
    "    metrics = {}\n",
    "    for idx, class_label in enumerate(classes):\n",
    "        TP = cm[idx, idx]  # True Positives for this class\n",
    "        FP = cm[:, idx].sum() - TP  # False Positives for this class\n",
    "        FN = cm[idx, :].sum() - TP  # False Negatives for this class\n",
    "        TN = cm.sum() - (TP + FP + FN)  # True Negatives for this class\n",
    "\n",
    "        metrics[class_label] = {\n",
    "            'TPR': TP / (TP + FN + 1e-10) if (TP + FN) > 0 else 0,\n",
    "            'TNR': TN / (TN + FP + 1e-10) if (TN + FP) > 0 else 0,\n",
    "            'FPR': FP / (FP + TN + 1e-10) if (FP + TN) > 0 else 0,\n",
    "            'FNR': FN / (FN + TP + 1e-10) if (FN + TP) > 0 else 0\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('C:/Users/ddihora1604/Downloads/IIT Patna/Task/Dataset 1/Student_performance_data.csv')\n",
    "\n",
    "# Take 20% of the data for faster processing (optional, comment out if you want to use full dataset)\n",
    "df = df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "# Rename the last column as 'label' if it's not already named that\n",
    "df.rename(columns={df.columns[-1]: 'label'}, inplace=True)\n",
    "\n",
    "# Check class distribution before resampling\n",
    "original_class_dist = df['label'].value_counts()\n",
    "print(f\"Original class distribution:\\n{original_class_dist}\")\n",
    "\n",
    "# Preprocessing: Handle missing values\n",
    "print(\"Preprocessing data...\")\n",
    "# Replace NaN values with column means for numerical columns\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# For categorical columns, fill with mode\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col != 'label':  # Don't replace label\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical features if any\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col != 'label':  # Don't encode label yet\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Encode the label column\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Extract features and target\n",
    "X = df.drop(columns=['label']).values\n",
    "y = df['label'].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize to store results\n",
    "results = []\n",
    "timing_results = []\n",
    "\n",
    "# Create K-fold cross-validation\n",
    "kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Fold-wise training and evaluation\n",
    "fold_idx = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(f\"Training fold {fold_idx}/{K_FOLDS}...\")\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Initialize RUSBoost\n",
    "    # Using Decision Tree as base estimator\n",
    "    rusboost = RUSBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=4),  # Changed from base_estimator to estimator\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        algorithm='SAMME.R',  # Use real-valued predictions\n",
    "        sampling_strategy='auto',  # Auto determine sampling strategy\n",
    "        replacement=False,  # Sample without replacement\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Record start time\n",
    "    start_train_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    rusboost.fit(X_train, y_train)\n",
    "    \n",
    "    train_time = time.time() - start_train_time\n",
    "    \n",
    "    # Make predictions\n",
    "    start_test_time = time.time()\n",
    "    y_pred = rusboost.predict(X_test)\n",
    "    test_time = time.time() - start_test_time\n",
    "    \n",
    "    # Record timing results\n",
    "    timing_results.append({\n",
    "        'Classifier': 'RUSBoost',\n",
    "        'Fold': fold_idx,\n",
    "        'Training Time (s)': train_time,\n",
    "        'Testing Time (s)': test_time,\n",
    "        'Total Time (s)': train_time + test_time\n",
    "    })\n",
    "    \n",
    "    # Compute metrics\n",
    "    unique_classes = np.unique(y)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=unique_classes)\n",
    "    cm_metrics = confusion_matrix_metrics(cm, unique_classes)\n",
    "    \n",
    "    # Plot and save confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=[class_names[i] if i < len(class_names) else i for i in unique_classes],\n",
    "                yticklabels=[class_names[i] if i < len(class_names) else i for i in unique_classes])\n",
    "    plt.title(f\"RUSBoost - Fold {fold_idx} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.savefig(f\"confusion_matrices/fold_{fold_idx}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate metrics per class\n",
    "    class_metrics_list = []\n",
    "    for class_label in unique_classes:\n",
    "        # Create binary labels for this class\n",
    "        y_test_bin = (y_test == class_label).astype(int)\n",
    "        y_pred_bin = (y_pred == class_label).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        class_specific_metrics = {\n",
    "            'Classifier': 'RUSBoost',\n",
    "            'Fold': fold_idx,\n",
    "            'Class': class_names[class_label] if class_label < len(class_names) else class_label,\n",
    "            'Accuracy': accuracy_score(y_test_bin, y_pred_bin),\n",
    "            'Precision': precision_score(y_test_bin, y_pred_bin, zero_division=0),\n",
    "            'Recall': recall_score(y_test_bin, y_pred_bin),\n",
    "            'F1 Score': f1_score(y_test_bin, y_pred_bin),\n",
    "            'Matthews Correlation Coefficient': matthews_corrcoef(y_test_bin, y_pred_bin),\n",
    "            'Cohen Kappa': cohen_kappa_score(y_test_bin, y_pred_bin),\n",
    "            'True Positive Rate (TPR)': cm_metrics[class_label]['TPR'],\n",
    "            'True Negative Rate (TNR)': cm_metrics[class_label]['TNR'],\n",
    "            'False Positive Rate (FPR)': cm_metrics[class_label]['FPR'],\n",
    "            'False Negative Rate (FNR)': cm_metrics[class_label]['FNR'],\n",
    "            'Training Time (s)': train_time,\n",
    "            'Testing Time (s)': test_time\n",
    "        }\n",
    "        class_metrics_list.append(class_specific_metrics)\n",
    "    \n",
    "    # Append results for this fold\n",
    "    results.extend(class_metrics_list)\n",
    "    fold_idx += 1\n",
    "\n",
    "# Create DataFrames for results\n",
    "timing_df = pd.DataFrame(timing_results)\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV\n",
    "timing_df.to_csv(\"results/time.csv\", index=False)\n",
    "results_df.to_csv(\"results/metrics.csv\", index=False)\n",
    "\n",
    "# Plot feature importance\n",
    "feature_names = df.drop(columns=['label']).columns.tolist()\n",
    "if hasattr(rusboost, 'feature_importances_'):\n",
    "    importances = rusboost.feature_importances_\n",
    "else:\n",
    "    # Calculate feature importance based on base estimators\n",
    "    importances = np.zeros(X.shape[1])\n",
    "    for estimator in rusboost.estimators_:\n",
    "        if hasattr(estimator, 'feature_importances_'):\n",
    "            importances += estimator.feature_importances_\n",
    "    \n",
    "    importances = importances / len(rusboost.estimators_)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('RUSBoost Feature Importances')\n",
    "plt.bar(range(len(indices)), importances[indices], align='center')\n",
    "plt.xticks(range(len(indices)), [feature_names[i] for i in indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visualizations/feature_importance.png\")\n",
    "plt.close()\n",
    "\n",
    "# Visualize ROC curves for multiclass\n",
    "try:\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    from itertools import cycle\n",
    "    \n",
    "    # Get probability estimates\n",
    "    y_score = rusboost.predict_proba(X_test)\n",
    "    \n",
    "    # Binarize the output for ROC curve\n",
    "    n_classes = len(unique_classes)\n",
    "    y_test_bin = label_binarize(y_test, classes=unique_classes)\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        if i < y_score.shape[1]:  # Check if there are probability scores for this class\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Plot ROC curves\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = cycle(['blue', 'red', 'green', 'cyan', 'magenta', 'yellow', 'black'])\n",
    "    \n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        if i in roc_auc and i < y_score.shape[1]:\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                    label=f'ROC curve of class {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for RUSBoost')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(\"visualizations/roc_curves.png\")\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error plotting ROC curves: {e}\")\n",
    "\n",
    "# Generate a pair plot for the most important features\n",
    "if len(feature_names) > 4:\n",
    "    top_indices = indices[:4]\n",
    "    top_features = [feature_names[i] for i in top_indices]\n",
    "else:\n",
    "    top_features = feature_names\n",
    "\n",
    "top_features_df = df[top_features + ['label']].copy()\n",
    "top_features_df['label'] = label_encoder.inverse_transform(top_features_df['label'])\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(top_features_df, hue='label')\n",
    "plt.savefig(\"visualizations/pairplot.png\")\n",
    "plt.close()\n",
    "\n",
    "# Visualize the class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts = pd.Series(label_encoder.inverse_transform(y)).value_counts()\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visualizations/class_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plot learning curve if possible\n",
    "try:\n",
    "    from sklearn.model_selection import learning_curve\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        rusboost, X, y, cv=3, scoring='accuracy', n_jobs=-1, \n",
    "        train_sizes=np.linspace(0.1, 1.0, 5)\n",
    "    )\n",
    "    \n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training accuracy')\n",
    "    plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "    plt.plot(train_sizes, test_mean, color='green', marker='s', markersize=5, label='Validation accuracy')\n",
    "    plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "    plt.title('Learning Curve for RUSBoost')\n",
    "    plt.xlabel('Training Set Size')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"visualizations/learning_curve.png\")\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error plotting learning curve: {e}\")\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Classification Metrics Across Folds:\")\n",
    "print(results_df.head())\n",
    "\n",
    "\n",
    "# Calculate and display average metrics across folds\n",
    "avg_metrics = results_df.groupby(['Classifier', 'Class']).mean().reset_index()\n",
    "avg_metrics.to_csv(\"results/avg_metrics.csv\", index=False)\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(avg_metrics[['Classifier', 'Class', 'Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
    "\n",
    "print(\"RUSBoost implementation completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
