{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Preprocessing data...\n",
      "Training fold 1/2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ddihora1604\\AppData\\Local\\Temp\\ipykernel_12632\\2409446453.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4458 - loss: 2.1275 - val_accuracy: 0.7614 - val_loss: 0.6442\n",
      "Epoch 2/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.6584 - val_accuracy: 0.7788 - val_loss: 0.5403\n",
      "Epoch 3/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7600 - loss: 0.5671 - val_accuracy: 0.7863 - val_loss: 0.4948\n",
      "Epoch 4/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7731 - loss: 0.5261 - val_accuracy: 0.7891 - val_loss: 0.4773\n",
      "Epoch 5/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7762 - loss: 0.5096 - val_accuracy: 0.7943 - val_loss: 0.4689\n",
      "Epoch 6/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7817 - loss: 0.4963 - val_accuracy: 0.7982 - val_loss: 0.4621\n",
      "Epoch 7/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7853 - loss: 0.4882 - val_accuracy: 0.7998 - val_loss: 0.4544\n",
      "Epoch 8/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 0.4800 - val_accuracy: 0.7998 - val_loss: 0.4504\n",
      "Epoch 9/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7912 - loss: 0.4716 - val_accuracy: 0.8032 - val_loss: 0.4394\n",
      "Epoch 10/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7972 - loss: 0.4637 - val_accuracy: 0.8106 - val_loss: 0.4326\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training fold 2/2...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4703 - loss: 2.1495 - val_accuracy: 0.7640 - val_loss: 0.6151\n",
      "Epoch 2/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7498 - loss: 0.5994 - val_accuracy: 0.7825 - val_loss: 0.5175\n",
      "Epoch 3/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7711 - loss: 0.5284 - val_accuracy: 0.7830 - val_loss: 0.4956\n",
      "Epoch 4/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7780 - loss: 0.5030 - val_accuracy: 0.7848 - val_loss: 0.4808\n",
      "Epoch 5/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 0.4934 - val_accuracy: 0.7880 - val_loss: 0.4773\n",
      "Epoch 6/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7865 - loss: 0.4844 - val_accuracy: 0.7951 - val_loss: 0.4665\n",
      "Epoch 7/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7885 - loss: 0.4759 - val_accuracy: 0.7953 - val_loss: 0.4631\n",
      "Epoch 8/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7919 - loss: 0.4664 - val_accuracy: 0.7978 - val_loss: 0.4577\n",
      "Epoch 9/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7949 - loss: 0.4633 - val_accuracy: 0.8021 - val_loss: 0.4531\n",
      "Epoch 10/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7953 - loss: 0.4594 - val_accuracy: 0.8019 - val_loss: 0.4503\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2999: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3000: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Metrics Across Folds:\n",
      "  Classifier  Fold  Class  Accuracy  Precision    Recall  F1 Score  \\\n",
      "0        RNN     1      0  0.999954   0.000000  0.000000  0.000000   \n",
      "1        RNN     1      1  0.985924   0.633495  0.988636  0.772189   \n",
      "2        RNN     1      2  0.999954   0.000000  0.000000  0.000000   \n",
      "3        RNN     1      3  0.999863   0.000000  0.000000  0.000000   \n",
      "4        RNN     1      4  0.999314   0.939850  0.946970  0.943396   \n",
      "\n",
      "   Matthews Correlation Coefficient  Cohen Kappa  True Positive Rate (TPR)  \\\n",
      "0                          0.000000     0.000000                  0.000000   \n",
      "1                          0.785531     0.765286                  0.988636   \n",
      "2                          0.000000     0.000000                  0.000000   \n",
      "3                          0.000000     0.000000                  0.000000   \n",
      "4                          0.943058     0.943051                  0.946970   \n",
      "\n",
      "   True Negative Rate (TNR)  False Positive Rate (FPR)  \\\n",
      "0                  1.000000                   0.000000   \n",
      "1                  0.985857                   0.014143   \n",
      "2                  1.000000                   0.000000   \n",
      "3                  1.000000                   0.000000   \n",
      "4                  0.999632                   0.000368   \n",
      "\n",
      "   False Negative Rate (FNR)  Training Time (s)  Testing Time (s)  \n",
      "0                   1.000000          14.996533          1.151739  \n",
      "1                   0.011364          14.996533          1.151739  \n",
      "2                   1.000000          14.996533          1.151739  \n",
      "3                   1.000000          14.996533          1.151739  \n",
      "4                   0.053030          14.996533          1.151739  \n",
      "\n",
      "Average Metrics Across Folds:\n",
      "   Classifier  Class  Accuracy  Precision    Recall  F1 Score\n",
      "0         RNN      0  0.999954   0.000000  0.000000  0.000000\n",
      "1         RNN      1  0.986541   0.641180  0.976461  0.773964\n",
      "2         RNN      2  0.999954   0.000000  0.000000  0.000000\n",
      "3         RNN      3  0.999909   0.000000  0.000000  0.000000\n",
      "4         RNN      4  0.998880   0.876704  0.970037  0.918903\n",
      "5         RNN      5  0.999589   0.000000  0.000000  0.000000\n",
      "6         RNN      6  0.999017   0.994911  0.998812  0.996849\n",
      "7         RNN      7  0.999657   0.997807  0.969759  0.983581\n",
      "8         RNN      8  0.999566   0.997382  0.997639  0.997510\n",
      "9         RNN      9  0.999771   0.999483  0.997910  0.998696\n",
      "10        RNN     10  0.954160   0.673196  0.958877  0.790865\n",
      "11        RNN     11  0.999634   0.000000  0.000000  0.000000\n",
      "12        RNN     12  0.965106   0.856915  0.677807  0.750853\n",
      "13        RNN     13  0.947465   0.652659  0.954125  0.774949\n",
      "14        RNN     14  0.950504   0.704703  0.980125  0.819898\n",
      "15        RNN     15  0.998857   0.865958  0.986699  0.922118\n",
      "16        RNN     16  0.996275   0.305556  0.032147  0.058006\n",
      "17        RNN     17  0.999794   0.000000  0.000000  0.000000\n",
      "18        RNN     18  0.998766   0.583333  0.174552  0.262500\n",
      "19        RNN     19  0.962478   0.663023  0.301873  0.371656\n",
      "20        RNN     20  0.947168   0.618105  0.128876  0.210290\n",
      "21        RNN     21  0.950070   0.897226  0.316711  0.468161\n",
      "22        RNN     22  0.994081   0.691134  0.258574  0.358295\n",
      "23        RNN     23  0.983456   0.570592  0.997921  0.726009\n",
      "24        RNN     24  0.983250   0.000000  0.000000  0.000000\n",
      "25        RNN     25  0.999863   0.996350  0.996479  0.996409\n",
      "26        RNN     26  0.997372   0.503135  0.270542  0.350243\n",
      "27        RNN     27  0.998218   0.000000  0.000000  0.000000\n",
      "28        RNN     28  0.999977   0.000000  0.000000  0.000000\n",
      "29        RNN     29  0.998195   0.000000  0.000000  0.000000\n",
      "30        RNN     30  0.999954   0.000000  0.000000  0.000000\n",
      "31        RNN     31  0.999954   0.000000  0.000000  0.000000\n",
      "32        RNN     32  0.999132   0.190476  0.285714  0.228571\n",
      "33        RNN     33  0.999886   0.000000  0.000000  0.000000\n",
      "RNN Classifier implementation completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             balanced_accuracy_score, confusion_matrix,\n",
    "                             matthews_corrcoef, cohen_kappa_score)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Set the number of K folds\n",
    "K_FOLDS = 2\n",
    "\n",
    "# Create directories to save results\n",
    "os.makedirs(\"confusion_matrices\", exist_ok=True)\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Helper function for confusion matrix metrics\n",
    "def confusion_matrix_metrics(cm, classes):\n",
    "    metrics = {}\n",
    "    for idx, class_label in enumerate(classes):\n",
    "        TP = cm[idx, idx]  # True Positives for this class\n",
    "        FP = cm[:, idx].sum() - TP  # False Positives for this class\n",
    "        FN = cm[idx, :].sum() - TP  # False Negatives for this class\n",
    "        TN = cm.sum() - (TP + FP + FN)  # True Negatives for this class\n",
    "\n",
    "        metrics[class_label] = {\n",
    "            'TPR': TP / (TP + FN + 1e-10) if (TP + FN) > 0 else 0,\n",
    "            'TNR': TN / (TN + FP + 1e-10) if (TN + FP) > 0 else 0,\n",
    "            'FPR': FP / (FP + TN + 1e-10) if (FP + TN) > 0 else 0,\n",
    "            'FNR': FN / (FN + TP + 1e-10) if (FN + TP) > 0 else 0\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('C:/Users/ddihora1604/Downloads/IIT Patna/Task/Dataset 2/part-00001_preprocessed_dataset.csv')\n",
    "\n",
    "# Take 20% of the data for faster processing (optional, comment out if you want to use full dataset)\n",
    "df = df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "# Rename the last column as 'label' if it's not already named that\n",
    "df.rename(columns={df.columns[-1]: 'label'}, inplace=True)\n",
    "\n",
    "# Preprocessing: Handle missing values\n",
    "print(\"Preprocessing data...\")\n",
    "# Replace NaN values with column means for numerical columns\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# For categorical columns, fill with mode\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col != 'label':  # Don't replace label\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical features if any\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col != 'label':  # Don't encode label yet\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Encode the label column\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Extract features and target\n",
    "X = df.drop(columns=['label']).values\n",
    "y = df['label'].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape input for RNN (samples, timesteps, features)\n",
    "# Treat each feature as a time step for simplicity\n",
    "X_reshaped = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "# Initialize to store results\n",
    "results = []\n",
    "timing_results = []\n",
    "\n",
    "# Create K-fold cross-validation\n",
    "kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Function to build the RNN model\n",
    "def build_rnn_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=input_shape, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Fold-wise training and evaluation\n",
    "fold_idx = 1\n",
    "for train_index, test_index in kf.split(X_reshaped):\n",
    "    print(f\"Training fold {fold_idx}/{K_FOLDS}...\")\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test = X_reshaped[train_index], X_reshaped[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Convert labels to one-hot encoding for RNN\n",
    "    y_train_onehot = to_categorical(y_train, num_classes=num_classes)\n",
    "    \n",
    "    # Build and train the model\n",
    "    rnn_model = build_rnn_model(input_shape=(X_train.shape[1], X_train.shape[2]), num_classes=num_classes)\n",
    "    \n",
    "    # Record start time\n",
    "    start_train_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    history = rnn_model.fit(\n",
    "        X_train, y_train_onehot,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    train_time = time.time() - start_train_time\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'RNN Accuracy - Fold {fold_idx}')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'RNN Loss - Fold {fold_idx}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"visualizations/training_history_fold_{fold_idx}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Make predictions\n",
    "    start_test_time = time.time()\n",
    "    y_pred_proba = rnn_model.predict(X_test)\n",
    "    test_time = time.time() - start_test_time\n",
    "    \n",
    "    # Convert probabilities to classes\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    \n",
    "    # Record timing results\n",
    "    timing_results.append({\n",
    "        'Classifier': 'RNN',\n",
    "        'Fold': fold_idx,\n",
    "        'Training Time (s)': train_time,\n",
    "        'Testing Time (s)': test_time,\n",
    "        'Total Time (s)': train_time + test_time\n",
    "    })\n",
    "    \n",
    "    # Compute metrics\n",
    "    unique_classes = np.unique(y)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=unique_classes)\n",
    "    cm_metrics = confusion_matrix_metrics(cm, unique_classes)\n",
    "    \n",
    "    # Plot and save confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=[class_names[i] if i < len(class_names) else i for i in unique_classes],\n",
    "                yticklabels=[class_names[i] if i < len(class_names) else i for i in unique_classes])\n",
    "    plt.title(f\"RNN - Fold {fold_idx} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.savefig(f\"confusion_matrices/fold_{fold_idx}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate metrics per class\n",
    "    class_metrics_list = []\n",
    "    for class_label in unique_classes:\n",
    "        # Create binary labels for this class\n",
    "        y_test_bin = (y_test == class_label).astype(int)\n",
    "        y_pred_bin = (y_pred == class_label).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        class_specific_metrics = {\n",
    "            'Classifier': 'RNN',\n",
    "            'Fold': fold_idx,\n",
    "            'Class': class_names[class_label] if class_label < len(class_names) else class_label,\n",
    "            'Accuracy': accuracy_score(y_test_bin, y_pred_bin),\n",
    "            'Precision': precision_score(y_test_bin, y_pred_bin, zero_division=0),\n",
    "            'Recall': recall_score(y_test_bin, y_pred_bin),\n",
    "            'F1 Score': f1_score(y_test_bin, y_pred_bin),\n",
    "            'Matthews Correlation Coefficient': matthews_corrcoef(y_test_bin, y_pred_bin),\n",
    "            'Cohen Kappa': cohen_kappa_score(y_test_bin, y_pred_bin),\n",
    "            'True Positive Rate (TPR)': cm_metrics[class_label]['TPR'],\n",
    "            'True Negative Rate (TNR)': cm_metrics[class_label]['TNR'],\n",
    "            'False Positive Rate (FPR)': cm_metrics[class_label]['FPR'],\n",
    "            'False Negative Rate (FNR)': cm_metrics[class_label]['FNR'],\n",
    "            'Training Time (s)': train_time,\n",
    "            'Testing Time (s)': test_time\n",
    "        }\n",
    "        class_metrics_list.append(class_specific_metrics)\n",
    "    \n",
    "    # Append results for this fold\n",
    "    results.extend(class_metrics_list)\n",
    "    fold_idx += 1\n",
    "\n",
    "# Create DataFrames for results\n",
    "timing_df = pd.DataFrame(timing_results)\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV\n",
    "timing_df.to_csv(\"results/time.csv\", index=False)\n",
    "results_df.to_csv(\"results/metrics.csv\", index=False)\n",
    "\n",
    "# Feature importance isn't directly available for RNNs, but we can try to visualize input-output correlations\n",
    "X_original = df.drop(columns=['label']).values  # Original features before reshaping\n",
    "feature_names = df.drop(columns=['label']).columns.tolist()\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = pd.DataFrame(X_original, columns=feature_names).corrwith(pd.Series(y)).sort_values(ascending=False)\n",
    "\n",
    "# Plot feature correlation with target\n",
    "plt.figure(figsize=(12, 8))\n",
    "corr_matrix.plot(kind='bar')\n",
    "plt.title('Feature Correlation with Target')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Correlation')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visualizations/feature_correlation.png\")\n",
    "plt.close()\n",
    "\n",
    "# Generate a pair plot for the most important features\n",
    "if len(feature_names) > 4:\n",
    "    top_features = corr_matrix.abs().nlargest(4).index.tolist()\n",
    "else:\n",
    "    top_features = feature_names\n",
    "\n",
    "top_features_df = df[top_features + ['label']].copy()\n",
    "top_features_df['label'] = label_encoder.inverse_transform(top_features_df['label'])\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(top_features_df, hue='label')\n",
    "plt.savefig(\"visualizations/pairplot.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Classification Metrics Across Folds:\")\n",
    "print(results_df.head())\n",
    "\n",
    "\n",
    "# Calculate and display average metrics across folds\n",
    "avg_metrics = results_df.groupby(['Classifier', 'Class']).mean().reset_index()\n",
    "avg_metrics.to_csv(\"results/avg_metrics.csv\", index=False)\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(avg_metrics[['Classifier', 'Class', 'Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
    "\n",
    "print(\"RNN Classifier implementation completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
