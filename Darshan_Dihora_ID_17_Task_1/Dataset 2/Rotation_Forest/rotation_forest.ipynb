{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Preprocessing data...\n",
      "Training fold 1/2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ddihora1604\\AppData\\Local\\Temp\\ipykernel_23536\\1547136824.py:161: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2/2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2999: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\ddihora1604\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3000: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Metrics Across Folds:\n",
      "       Classifier  Fold  Class  Accuracy  Precision    Recall  F1 Score  \\\n",
      "0  RotationForest     1      0  0.999954   0.000000  0.000000  0.000000   \n",
      "1  RotationForest     1      1  0.992688   0.788401  0.952652  0.862779   \n",
      "2  RotationForest     1      2  0.999954   0.000000  0.000000  0.000000   \n",
      "3  RotationForest     1      3  0.999863   0.000000  0.000000  0.000000   \n",
      "4  RotationForest     1      4  0.999863   1.000000  0.977273  0.988506   \n",
      "\n",
      "   Matthews Correlation Coefficient  Cohen Kappa  True Positive Rate (TPR)  \\\n",
      "0                          0.000000     0.000000                  0.000000   \n",
      "1                          0.863118     0.859057                  0.952652   \n",
      "2                          0.000000     0.000000                  0.000000   \n",
      "3                          0.000000     0.000000                  0.000000   \n",
      "4                          0.988503     0.988437                  0.977273   \n",
      "\n",
      "   True Negative Rate (TNR)  False Positive Rate (FPR)  \\\n",
      "0                  1.000000                   0.000000   \n",
      "1                  0.993678                   0.006322   \n",
      "2                  1.000000                   0.000000   \n",
      "3                  1.000000                   0.000000   \n",
      "4                  1.000000                   0.000000   \n",
      "\n",
      "   False Negative Rate (FNR)  Training Time (s)  Testing Time (s)  \n",
      "0                   1.000000           4.331388          0.167371  \n",
      "1                   0.047348           4.331388          0.167371  \n",
      "2                   1.000000           4.331388          0.167371  \n",
      "3                   1.000000           4.331388          0.167371  \n",
      "4                   0.022727           4.331388          0.167371  \n",
      "\n",
      "Average Metrics Across Folds:\n",
      "        Classifier  Class  Accuracy  Precision    Recall  F1 Score\n",
      "0   RotationForest      0  0.999954   0.000000  0.000000  0.000000\n",
      "1   RotationForest      1  0.992550   0.786457  0.938627  0.855797\n",
      "2   RotationForest      2  0.999954   0.000000  0.000000  0.000000\n",
      "3   RotationForest      3  0.999909   0.000000  0.000000  0.000000\n",
      "4   RotationForest      4  0.999749   0.973856  0.988636  0.980830\n",
      "5   RotationForest      5  0.999726   0.675000  0.675000  0.675000\n",
      "6   RotationForest      6  0.999703   0.999113  0.998961  0.999037\n",
      "7   RotationForest      7  0.999612   0.979106  0.984809  0.981813\n",
      "8   RotationForest      8  0.999634   0.997375  0.998420  0.997898\n",
      "9   RotationForest      9  0.999863   0.999736  0.998702  0.999219\n",
      "10  RotationForest     10  0.999109   0.994190  0.995962  0.995075\n",
      "11  RotationForest     11  0.999657   0.666667  0.245455  0.357143\n",
      "12  RotationForest     12  0.999771   0.999118  0.997931  0.998524\n",
      "13  RotationForest     13  0.999497   0.998308  0.996383  0.997344\n",
      "14  RotationForest     14  0.999154   0.996268  0.996400  0.996330\n",
      "15  RotationForest     15  0.999634   0.966244  0.979850  0.972986\n",
      "16  RotationForest     16  0.996389   0.498574  0.410534  0.450145\n",
      "17  RotationForest     17  0.999794   0.250000  0.250000  0.250000\n",
      "18  RotationForest     18  0.999703   0.937500  0.846547  0.889359\n",
      "19  RotationForest     19  0.999314   0.992624  0.991588  0.992104\n",
      "20  RotationForest     20  0.999543   0.994246  0.997530  0.995885\n",
      "21  RotationForest     21  0.999040   0.994115  0.992054  0.993065\n",
      "22  RotationForest     22  0.995750   0.714281  0.601474  0.653008\n",
      "23  RotationForest     23  0.999520   0.987552  0.990636  0.989091\n",
      "24  RotationForest     24  0.999269   0.986057  0.970348  0.978097\n",
      "25  RotationForest     25  0.999909   0.998778  0.996479  0.997625\n",
      "26  RotationForest     26  0.998263   0.703917  0.582623  0.630865\n",
      "27  RotationForest     27  0.997623   0.238325  0.152824  0.186207\n",
      "28  RotationForest     28  0.999954   0.000000  0.000000  0.000000\n",
      "29  RotationForest     29  0.998469   0.642857  0.342747  0.446966\n",
      "30  RotationForest     30  0.999931   0.000000  0.000000  0.000000\n",
      "31  RotationForest     31  0.999954   0.000000  0.000000  0.000000\n",
      "32  RotationForest     32  0.999543   0.723077  0.718045  0.696691\n",
      "33  RotationForest     33  0.999886   0.000000  0.000000  0.000000\n",
      "Rotation Forest implementation completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             balanced_accuracy_score, confusion_matrix,\n",
    "                             matthews_corrcoef, cohen_kappa_score)\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the number of K folds\n",
    "K_FOLDS = 2\n",
    "\n",
    "# Create directories to save results\n",
    "os.makedirs(\"confusion_matrices\", exist_ok=True)\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Helper function for confusion matrix metrics\n",
    "def confusion_matrix_metrics(cm, classes):\n",
    "    metrics = {}\n",
    "    for idx, class_label in enumerate(classes):\n",
    "        TP = cm[idx, idx]  # True Positives for this class\n",
    "        FP = cm[:, idx].sum() - TP  # False Positives for this class\n",
    "        FN = cm[idx, :].sum() - TP  # False Negatives for this class\n",
    "        TN = cm.sum() - (TP + FP + FN)  # True Negatives for this class\n",
    "\n",
    "        metrics[class_label] = {\n",
    "            'TPR': TP / (TP + FN + 1e-10) if (TP + FN) > 0 else 0,\n",
    "            'TNR': TN / (TN + FP + 1e-10) if (TN + FP) > 0 else 0,\n",
    "            'FPR': FP / (FP + TN + 1e-10) if (FP + TN) > 0 else 0,\n",
    "            'FNR': FN / (FN + TP + 1e-10) if (FN + TP) > 0 else 0\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "# Rotation Forest implementation\n",
    "class RotationForestClassifier:\n",
    "    def __init__(self, n_estimators=10, feature_groups=3, max_features=0.75, random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.feature_groups = feature_groups\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        self.estimators = []\n",
    "        self.feature_indices = []\n",
    "        self.pcas = []\n",
    "        self.feature_importances_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.estimators = []\n",
    "        self.feature_indices = []\n",
    "        self.pcas = []\n",
    "        \n",
    "        # Initialize feature importance\n",
    "        all_importances = np.zeros((self.n_estimators, n_features))\n",
    "        \n",
    "        # Set random seed for reproducibility\n",
    "        np.random.seed(self.random_state)\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            # Randomly determine number of features per group\n",
    "            max_features = int(n_features * self.max_features) if isinstance(self.max_features, float) else self.max_features\n",
    "            features_per_group = max(1, max_features // self.feature_groups)\n",
    "            \n",
    "            # Shuffle feature indices\n",
    "            feature_indices = np.random.permutation(n_features)\n",
    "            \n",
    "            # Group features\n",
    "            groups = [feature_indices[j:j+features_per_group] for j in range(0, len(feature_indices), features_per_group)]\n",
    "            \n",
    "            # Create rotation matrix (identity initially)\n",
    "            R = np.zeros((n_features, n_features))\n",
    "            \n",
    "            # Apply PCA on each group\n",
    "            for group in groups:\n",
    "                if len(group) > 0:\n",
    "                    # Select subset of data for this group\n",
    "                    X_subset = X[:, group]\n",
    "                    \n",
    "                    # Apply PCA\n",
    "                    pca = PCA(random_state=self.random_state+i)\n",
    "                    pca.fit(X_subset)\n",
    "                    \n",
    "                    # Fill the rotation matrix with the PCA components\n",
    "                    for j, idx in enumerate(group):\n",
    "                        if j < len(pca.components_):\n",
    "                            for k, comp_idx in enumerate(group):\n",
    "                                if k < len(pca.components_[j]):\n",
    "                                    R[idx, comp_idx] = pca.components_[j, k]\n",
    "            \n",
    "            # Transform the data\n",
    "            X_transformed = X @ R\n",
    "            \n",
    "            # Train a decision tree on the transformed data\n",
    "            tree = DecisionTreeClassifier(random_state=self.random_state+i)\n",
    "            tree.fit(X_transformed, y)\n",
    "            \n",
    "            # Store the estimator, rotation matrix, and feature indices\n",
    "            self.estimators.append(tree)\n",
    "            self.feature_indices.append(feature_indices)\n",
    "            self.pcas.append(R)\n",
    "            \n",
    "            # Get feature importances from this tree\n",
    "            importance = np.zeros(n_features)\n",
    "            for idx, imp in zip(range(n_features), tree.feature_importances_):\n",
    "                importance[idx] = imp\n",
    "            all_importances[i] = importance\n",
    "        \n",
    "        # Average feature importances across all trees\n",
    "        self.feature_importances_ = np.mean(all_importances, axis=0)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((X.shape[0], len(self.estimators)))\n",
    "        \n",
    "        for i, (tree, R) in enumerate(zip(self.estimators, self.pcas)):\n",
    "            # Transform the data using the rotation matrix\n",
    "            X_transformed = X @ R\n",
    "            \n",
    "            # Make predictions\n",
    "            predictions[:, i] = tree.predict(X_transformed)\n",
    "        \n",
    "        # Majority voting\n",
    "        return np.array([np.bincount(predictions[i, :].astype(int)).argmax() for i in range(X.shape[0])])\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        probas = np.zeros((X.shape[0], len(np.unique(self.estimators[0].predict(X @ self.pcas[0])))))\n",
    "        \n",
    "        for i, (tree, R) in enumerate(zip(self.estimators, self.pcas)):\n",
    "            # Transform the data using the rotation matrix\n",
    "            X_transformed = X @ R\n",
    "            \n",
    "            # Make probability predictions\n",
    "            probas += tree.predict_proba(X_transformed)\n",
    "        \n",
    "        # Average probabilities\n",
    "        return probas / len(self.estimators)\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('C:/Users/ddihora1604/Downloads/IIT Patna/Task/Dataset 2/part-00001_preprocessed_dataset.csv')\n",
    "\n",
    "# Take 20% of the data for faster processing (optional, comment out if you want to use full dataset)\n",
    "df = df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "# Rename the last column as 'label' if it's not already named that\n",
    "df.rename(columns={df.columns[-1]: 'label'}, inplace=True)\n",
    "\n",
    "# Preprocessing: Handle missing values\n",
    "print(\"Preprocessing data...\")\n",
    "# Replace NaN values with column means for numerical columns\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# For categorical columns, fill with mode\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col != 'label':  # Don't replace label\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical features if any\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col != 'label':  # Don't encode label yet\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Encode the label column\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Extract features and target\n",
    "X = df.drop(columns=['label']).values\n",
    "y = df['label'].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize to store results\n",
    "results = []\n",
    "timing_results = []\n",
    "\n",
    "# Create K-fold cross-validation\n",
    "kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Fold-wise training and evaluation\n",
    "fold_idx = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(f\"Training fold {fold_idx}/{K_FOLDS}...\")\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Initialize Rotation Forest\n",
    "    rotation_forest = RotationForestClassifier(n_estimators=10, feature_groups=3, random_state=42)\n",
    "    \n",
    "    # Record start time\n",
    "    start_train_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    rotation_forest.fit(X_train, y_train)\n",
    "    \n",
    "    train_time = time.time() - start_train_time\n",
    "    \n",
    "    # Make predictions\n",
    "    start_test_time = time.time()\n",
    "    y_pred = rotation_forest.predict(X_test)\n",
    "    test_time = time.time() - start_test_time\n",
    "    \n",
    "    # Record timing results\n",
    "    timing_results.append({\n",
    "        'Classifier': 'RotationForest',\n",
    "        'Fold': fold_idx,\n",
    "        'Training Time (s)': train_time,\n",
    "        'Testing Time (s)': test_time,\n",
    "        'Total Time (s)': train_time + test_time\n",
    "    })\n",
    "    \n",
    "    # Compute metrics\n",
    "    unique_classes = np.unique(y)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=unique_classes)\n",
    "    cm_metrics = confusion_matrix_metrics(cm, unique_classes)\n",
    "    \n",
    "    # Plot and save confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=[class_names[i] if i < len(class_names) else i for i in unique_classes],\n",
    "                yticklabels=[class_names[i] if i < len(class_names) else i for i in unique_classes])\n",
    "    plt.title(f\"Rotation Forest - Fold {fold_idx} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.savefig(f\"confusion_matrices/fold_{fold_idx}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate metrics per class\n",
    "    class_metrics_list = []\n",
    "    for class_label in unique_classes:\n",
    "        # Create binary labels for this class\n",
    "        y_test_bin = (y_test == class_label).astype(int)\n",
    "        y_pred_bin = (y_pred == class_label).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        class_specific_metrics = {\n",
    "            'Classifier': 'RotationForest',\n",
    "            'Fold': fold_idx,\n",
    "            'Class': class_names[class_label] if class_label < len(class_names) else class_label,\n",
    "            'Accuracy': accuracy_score(y_test_bin, y_pred_bin),\n",
    "            'Precision': precision_score(y_test_bin, y_pred_bin, zero_division=0),\n",
    "            'Recall': recall_score(y_test_bin, y_pred_bin),\n",
    "            'F1 Score': f1_score(y_test_bin, y_pred_bin),\n",
    "            'Matthews Correlation Coefficient': matthews_corrcoef(y_test_bin, y_pred_bin),\n",
    "            'Cohen Kappa': cohen_kappa_score(y_test_bin, y_pred_bin),\n",
    "            'True Positive Rate (TPR)': cm_metrics[class_label]['TPR'],\n",
    "            'True Negative Rate (TNR)': cm_metrics[class_label]['TNR'],\n",
    "            'False Positive Rate (FPR)': cm_metrics[class_label]['FPR'],\n",
    "            'False Negative Rate (FNR)': cm_metrics[class_label]['FNR'],\n",
    "            'Training Time (s)': train_time,\n",
    "            'Testing Time (s)': test_time\n",
    "        }\n",
    "        class_metrics_list.append(class_specific_metrics)\n",
    "    \n",
    "    # Append results for this fold\n",
    "    results.extend(class_metrics_list)\n",
    "    fold_idx += 1\n",
    "\n",
    "# Create DataFrames for results\n",
    "timing_df = pd.DataFrame(timing_results)\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV\n",
    "timing_df.to_csv(\"results/time.csv\", index=False)\n",
    "results_df.to_csv(\"results/metrics.csv\", index=False)\n",
    "\n",
    "# Plot feature importance\n",
    "if hasattr(rotation_forest, 'feature_importances_'):\n",
    "    feature_names = df.drop(columns=['label']).columns.tolist()\n",
    "    importances = rotation_forest.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title('Rotation Forest Feature Importances')\n",
    "    plt.bar(range(len(indices)), importances[indices], align='center')\n",
    "    plt.xticks(range(len(indices)), [feature_names[i] for i in indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualizations/feature_importance.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Generate a pair plot for the most important features\n",
    "feature_names = df.drop(columns=['label']).columns.tolist()\n",
    "\n",
    "# Create a correlation matrix for feature selection\n",
    "corr_matrix = pd.DataFrame(X, columns=feature_names).corrwith(pd.Series(y)).abs().sort_values(ascending=False)\n",
    "\n",
    "# Select top features\n",
    "if len(feature_names) > 4:\n",
    "    top_features = corr_matrix.nlargest(4).index.tolist()\n",
    "else:\n",
    "    top_features = feature_names\n",
    "\n",
    "top_features_df = df[top_features + ['label']].copy()\n",
    "top_features_df['label'] = label_encoder.inverse_transform(top_features_df['label'])\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(top_features_df, hue='label')\n",
    "plt.savefig(\"visualizations/pairplot.png\")\n",
    "plt.close()\n",
    "\n",
    "# Visualize the distribution of classes\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts = pd.Series(label_encoder.inverse_transform(y)).value_counts()\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visualizations/class_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Classification Metrics Across Folds:\")\n",
    "print(results_df.head())\n",
    "\n",
    "\n",
    "\n",
    "# Calculate and display average metrics across folds\n",
    "avg_metrics = results_df.groupby(['Classifier', 'Class']).mean().reset_index()\n",
    "avg_metrics.to_csv(\"results/avg_metrics.csv\", index=False)\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(avg_metrics[['Classifier', 'Class', 'Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
    "\n",
    "print(\"Rotation Forest implementation completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
